{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ros-guUeWRXe"
   },
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importazione file dataset e creazione di train, test e validation set.\n",
    "Le immagini vengono normalizzate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1708100730220,
     "user": {
      "displayName": "Gianluca Maccari",
      "userId": "05720923772203941125"
     },
     "user_tz": -60
    },
    "id": "7mF1YvipZGAq"
   },
   "outputs": [],
   "source": [
    "x = np.load(\"C:/Users/gianl/Downloads/pneumonia_images.npy\")\n",
    "y = np.load(\"C:/Users/gianl/Downloads/pneumonia_labels.npy\")\n",
    "\n",
    "#creazione dei vari dataset\n",
    "seed = 42\n",
    "#separazione train e test set\n",
    "train_images, test_images = train_test_split(x, test_size=0.1, random_state=seed)\n",
    "train_labels, test_labels = train_test_split(y, test_size=0.1, random_state=seed)\n",
    "\n",
    "#creazione validation set e train set\n",
    "x_valid_images = train_images[:500]/255.\n",
    "x_valid_labels = train_labels[:500]\n",
    "x_train_images = train_images[500:]/255.\n",
    "x_train_labels = train_labels[500:]\n",
    "\n",
    "#normalizzazione anche del test set\n",
    "test_images = test_images/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si può osservare come i dati del dataset non presentano errori o immagini compromesse, inoltre si osserva che le immagini possiedono un solo canale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errori nelle label:  0\n",
      "foto compromesse:  0\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#semplice verifica se ci siano dati mancanti o valori differenti da 0 e 1 per le label\n",
    "len_y = len(y)\n",
    "len_image = len(x[0])\n",
    "count_y = 0\n",
    "count_x = 0\n",
    "for i in range(len_y-1):\n",
    "    if y[i] != 0 and y[i] != 1:\n",
    "        count_y += 1\n",
    "    if len(x[i]) != len_image:\n",
    "        count_x += 1\n",
    "print(\"errori nelle label: \",count_y)\n",
    "print(\"foto compromesse: \",count_x)\n",
    "\n",
    "print(x[0].shape)\n",
    "\n",
    "plt.imshow(x[0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classe uno ha:  3882  elementi\n",
      "classe zero ha:  1349  elementi\n"
     ]
    }
   ],
   "source": [
    "#verifica sul numero di elementi per classe\n",
    "lab_one = 0\n",
    "lab_zero = 0\n",
    "for i in range(len_y-1):\n",
    "    if y[i] == 0:\n",
    "        lab_zero += 1\n",
    "    else:\n",
    "        lab_one += 1\n",
    "\n",
    "print(\"classe uno ha: \", lab_one,\" elementi\")\n",
    "print(\"classe zero ha: \", lab_zero,\" elementi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1708100730221,
     "user": {
      "displayName": "Gianluca Maccari",
      "userId": "05720923772203941125"
     },
     "user_tz": -60
    },
    "id": "BWpzcRmBky1D"
   },
   "outputs": [],
   "source": [
    "#funzioni utili\n",
    "\n",
    "def printResults(history):\n",
    "  pd.DataFrame(history.history).plot(figsize=(5, 3))\n",
    "  plt.grid(True)\n",
    "  plt.gca().set_ylim(0, 1)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8evNMcPP-2b1"
   },
   "source": [
    "## FNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8evNMcPP-2b1"
   },
   "source": [
    "Si inizia ad affrontare il problema con le reti neurali feedforward. Successivamente si passa alle reti cnn. \n",
    "Si esplorano più reti fnn in base al numero di layer e numero di unità per layer.\n",
    "Le reti avranno in comune gli ultimi 3 livelli densi da 32, 16 e 1 livello, mentre variano i primi livelli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definisco un modello per testare dei valori differenti per numero di unità e numero layer\n",
    "#i layer finali sono fissi con 32 unità e 16 unità, variano gli upper layer, i primi livelli\n",
    "def build_model(n_layers, units_array):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "    \n",
    "    for i in range(n_layers - 1):\n",
    "        model.add(keras.layers.Dense(units_array[i], activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "#funzione utile per addestrare un modello creato con la funziona sopra\n",
    "#l'addestramento viene sempre arrestato da early stopping, quindi il numero di epoche indicato è \n",
    "#sufficiente per l'addestramento completo\n",
    "def train_model(model):\n",
    "    model.fit(x_train_images, x_train_labels, epochs=100,\n",
    "                    verbose=0,\n",
    "                    validation_data=(x_valid_images, x_valid_labels),\n",
    "                    callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risultati su test set modello:\n",
      "layers:  4\n",
      "units:  [512, 256, 128, 64]\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9656\n",
      "loss:  0.10620541870594025\n",
      "accuracy:  0.9656488299369812\n",
      "\n",
      "\n",
      "risultati su test set modello:\n",
      "layers:  3\n",
      "units:  [256, 128, 64]\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1027 - accuracy: 0.9618\n",
      "loss:  0.1027301773428917\n",
      "accuracy:  0.9618320465087891\n",
      "\n",
      "\n",
      "risultati su test set modello:\n",
      "layers:  2\n",
      "units:  [128, 64]\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9637\n",
      "loss:  0.10555889457464218\n",
      "accuracy:  0.9637404680252075\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4 è il numero massimo di upper layer\n",
    "#il vettore numero di unità è [512,256,128,64]\n",
    "#se si volessero modificare i valori da testare: max_layer = len(n_units)\n",
    "n_units = [512,256,128,64]\n",
    "max_layer = 4\n",
    "\n",
    "loss_results = []\n",
    "accuracy_results = []\n",
    "\n",
    "model_list = []\n",
    "\n",
    "for i in range(max_layer-1):\n",
    "    if i == 0:\n",
    "        cur_model = build_model(max_layer,n_units)\n",
    "    else:\n",
    "        cur_model = build_model(max_layer-i,n_units[i:])\n",
    "\n",
    "    model_list.append(cur_model)\n",
    "    print(\"risultati su test set modello:\")\n",
    "    print(\"layers: \",max_layer-i)\n",
    "    print(\"units: \",n_units[i:])\n",
    "    \n",
    "    train_model(cur_model)\n",
    "    cur_loss, cur_acc = cur_model.evaluate(test_images, test_labels)\n",
    "    \n",
    "    print(\"loss: \",cur_loss)\n",
    "    print(\"accuracy: \",cur_acc)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    loss_results.append(cur_loss)\n",
    "    accuracy_results.append(cur_acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prendo la miglior rete tra quelle addestrate (la prima), aumento di molto il numero delle epoche e per ridurre l'overfitting si introducono dei livelli di dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.5887 - accuracy: 0.7160 - val_loss: 0.4116 - val_accuracy: 0.7240\n",
      "Epoch 2/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.3220 - accuracy: 0.8377 - val_loss: 0.2502 - val_accuracy: 0.8860\n",
      "Epoch 3/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2627 - accuracy: 0.9038 - val_loss: 0.2606 - val_accuracy: 0.8340\n",
      "Epoch 4/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2351 - accuracy: 0.9216 - val_loss: 0.1873 - val_accuracy: 0.9300\n",
      "Epoch 5/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2167 - accuracy: 0.9185 - val_loss: 0.2641 - val_accuracy: 0.8880\n",
      "Epoch 6/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.9254 - val_loss: 0.2058 - val_accuracy: 0.9260\n",
      "Epoch 7/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1975 - accuracy: 0.9308 - val_loss: 0.2055 - val_accuracy: 0.9120\n",
      "Epoch 8/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1976 - accuracy: 0.9297 - val_loss: 0.2053 - val_accuracy: 0.9220\n",
      "Epoch 9/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2122 - accuracy: 0.9209 - val_loss: 0.1684 - val_accuracy: 0.9320\n",
      "Epoch 10/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2385 - accuracy: 0.9114 - val_loss: 0.1799 - val_accuracy: 0.9300\n",
      "Epoch 11/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2184 - accuracy: 0.9142 - val_loss: 0.1772 - val_accuracy: 0.9360\n",
      "Epoch 12/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1843 - accuracy: 0.9278 - val_loss: 0.1724 - val_accuracy: 0.9320\n",
      "Epoch 13/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1808 - accuracy: 0.9368 - val_loss: 0.1634 - val_accuracy: 0.9340\n",
      "Epoch 14/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.9358 - val_loss: 0.1795 - val_accuracy: 0.9360\n",
      "Epoch 15/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.9346 - val_loss: 0.1850 - val_accuracy: 0.9320\n",
      "Epoch 16/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1748 - accuracy: 0.9361 - val_loss: 0.1996 - val_accuracy: 0.9380\n",
      "Epoch 17/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1798 - accuracy: 0.9304 - val_loss: 0.1623 - val_accuracy: 0.9360\n",
      "Epoch 18/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.9325 - val_loss: 0.1808 - val_accuracy: 0.9380\n",
      "Epoch 19/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1831 - accuracy: 0.9358 - val_loss: 0.1944 - val_accuracy: 0.9320\n",
      "Epoch 20/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2277 - accuracy: 0.9125 - val_loss: 0.2552 - val_accuracy: 0.8940\n",
      "Epoch 21/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1926 - accuracy: 0.9285 - val_loss: 0.1757 - val_accuracy: 0.9400\n",
      "Epoch 22/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1867 - accuracy: 0.9316 - val_loss: 0.1881 - val_accuracy: 0.9220\n",
      "Epoch 23/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1818 - accuracy: 0.9308 - val_loss: 0.1859 - val_accuracy: 0.9340\n",
      "Epoch 24/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1748 - accuracy: 0.9261 - val_loss: 0.1573 - val_accuracy: 0.9380\n",
      "Epoch 25/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1569 - accuracy: 0.9330 - val_loss: 0.1564 - val_accuracy: 0.9400\n",
      "Epoch 26/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1683 - accuracy: 0.9316 - val_loss: 0.1611 - val_accuracy: 0.9480\n",
      "Epoch 27/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1812 - accuracy: 0.9318 - val_loss: 0.1911 - val_accuracy: 0.9220\n",
      "Epoch 28/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2273 - accuracy: 0.8985 - val_loss: 0.2359 - val_accuracy: 0.9200\n",
      "Epoch 29/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2054 - accuracy: 0.9045 - val_loss: 0.1581 - val_accuracy: 0.9360\n",
      "Epoch 30/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1835 - accuracy: 0.9171 - val_loss: 0.1749 - val_accuracy: 0.9360\n",
      "Epoch 31/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1821 - accuracy: 0.9282 - val_loss: 0.1554 - val_accuracy: 0.9400\n",
      "Epoch 32/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1829 - accuracy: 0.9259 - val_loss: 0.1612 - val_accuracy: 0.9380\n",
      "Epoch 33/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1780 - accuracy: 0.9282 - val_loss: 0.1530 - val_accuracy: 0.9400\n",
      "Epoch 34/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.9289 - val_loss: 0.1563 - val_accuracy: 0.9460\n",
      "Epoch 35/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1706 - accuracy: 0.9332 - val_loss: 0.1659 - val_accuracy: 0.9440\n",
      "Epoch 36/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1513 - accuracy: 0.9404 - val_loss: 0.1868 - val_accuracy: 0.9440\n",
      "Epoch 37/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1665 - accuracy: 0.9325 - val_loss: 0.1504 - val_accuracy: 0.9420\n",
      "Epoch 38/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1745 - accuracy: 0.9266 - val_loss: 0.1523 - val_accuracy: 0.9440\n",
      "Epoch 39/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9351 - val_loss: 0.1490 - val_accuracy: 0.9420\n",
      "Epoch 40/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1592 - accuracy: 0.9339 - val_loss: 0.1610 - val_accuracy: 0.9380\n",
      "Epoch 41/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1645 - accuracy: 0.9339 - val_loss: 0.1587 - val_accuracy: 0.9400\n",
      "Epoch 42/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1526 - accuracy: 0.9394 - val_loss: 0.1575 - val_accuracy: 0.9400\n",
      "Epoch 43/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1497 - accuracy: 0.9361 - val_loss: 0.1607 - val_accuracy: 0.9380\n",
      "Epoch 44/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1595 - accuracy: 0.9306 - val_loss: 0.1728 - val_accuracy: 0.9440\n",
      "Epoch 45/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1606 - accuracy: 0.9311 - val_loss: 0.1770 - val_accuracy: 0.9320\n",
      "Epoch 46/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1551 - accuracy: 0.9346 - val_loss: 0.1608 - val_accuracy: 0.9480\n",
      "Epoch 47/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1582 - accuracy: 0.9339 - val_loss: 0.2093 - val_accuracy: 0.9340\n",
      "Epoch 48/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9399 - val_loss: 0.1700 - val_accuracy: 0.9420\n",
      "Epoch 49/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1588 - accuracy: 0.9316 - val_loss: 0.1589 - val_accuracy: 0.9420\n",
      "Epoch 50/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1554 - accuracy: 0.9325 - val_loss: 0.1551 - val_accuracy: 0.9440\n",
      "Epoch 51/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1508 - accuracy: 0.9316 - val_loss: 0.1536 - val_accuracy: 0.9400\n",
      "Epoch 52/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1529 - accuracy: 0.9365 - val_loss: 0.1593 - val_accuracy: 0.9360\n",
      "Epoch 53/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9361 - val_loss: 0.1609 - val_accuracy: 0.9460\n",
      "Epoch 54/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9382 - val_loss: 0.1593 - val_accuracy: 0.9460\n",
      "Epoch 55/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1552 - accuracy: 0.9335 - val_loss: 0.1506 - val_accuracy: 0.9440\n",
      "Epoch 56/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1631 - accuracy: 0.9346 - val_loss: 0.1948 - val_accuracy: 0.9360\n",
      "Epoch 57/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9425 - val_loss: 0.1716 - val_accuracy: 0.9440\n",
      "Epoch 58/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9365 - val_loss: 0.1526 - val_accuracy: 0.9380\n",
      "Epoch 59/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1721 - accuracy: 0.9259 - val_loss: 0.1568 - val_accuracy: 0.9400\n",
      "Epoch 60/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1463 - accuracy: 0.9382 - val_loss: 0.1577 - val_accuracy: 0.9340\n",
      "Epoch 61/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1671 - accuracy: 0.9273 - val_loss: 0.1654 - val_accuracy: 0.9440\n",
      "Epoch 62/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.9318 - val_loss: 0.1533 - val_accuracy: 0.9440\n",
      "Epoch 63/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9399 - val_loss: 0.1511 - val_accuracy: 0.9480\n",
      "Epoch 64/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9356 - val_loss: 0.1717 - val_accuracy: 0.9460\n",
      "Epoch 65/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9408 - val_loss: 0.1514 - val_accuracy: 0.9460\n",
      "Epoch 66/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1521 - accuracy: 0.9389 - val_loss: 0.1612 - val_accuracy: 0.9460\n",
      "Epoch 67/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1596 - accuracy: 0.9363 - val_loss: 0.1614 - val_accuracy: 0.9420\n",
      "Epoch 68/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9335 - val_loss: 0.1580 - val_accuracy: 0.9440\n",
      "Epoch 69/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9413 - val_loss: 0.1573 - val_accuracy: 0.9440\n",
      "Epoch 70/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1519 - accuracy: 0.9382 - val_loss: 0.1525 - val_accuracy: 0.9460\n",
      "Epoch 71/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1417 - accuracy: 0.9420 - val_loss: 0.1529 - val_accuracy: 0.9440\n",
      "Epoch 72/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1532 - accuracy: 0.9370 - val_loss: 0.1515 - val_accuracy: 0.9500\n",
      "Epoch 73/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9380 - val_loss: 0.1551 - val_accuracy: 0.9440\n",
      "Epoch 74/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9406 - val_loss: 0.1634 - val_accuracy: 0.9440\n",
      "Epoch 75/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1421 - accuracy: 0.9423 - val_loss: 0.1919 - val_accuracy: 0.9080\n",
      "Epoch 76/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1397 - accuracy: 0.9404 - val_loss: 0.1850 - val_accuracy: 0.9460\n",
      "Epoch 77/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9361 - val_loss: 0.1504 - val_accuracy: 0.9480\n",
      "Epoch 78/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9437 - val_loss: 0.1521 - val_accuracy: 0.9480\n",
      "Epoch 79/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1665 - accuracy: 0.9356 - val_loss: 0.1503 - val_accuracy: 0.9400\n",
      "Epoch 80/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1713 - accuracy: 0.9339 - val_loss: 0.1548 - val_accuracy: 0.9480\n",
      "Epoch 81/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2184 - accuracy: 0.8966 - val_loss: 0.1728 - val_accuracy: 0.9400\n",
      "Epoch 82/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1576 - accuracy: 0.9356 - val_loss: 0.1717 - val_accuracy: 0.9360\n",
      "Epoch 83/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1511 - accuracy: 0.9375 - val_loss: 0.1739 - val_accuracy: 0.9300\n",
      "Epoch 84/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1398 - accuracy: 0.9425 - val_loss: 0.1855 - val_accuracy: 0.9380\n",
      "Epoch 85/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1463 - accuracy: 0.9368 - val_loss: 0.1559 - val_accuracy: 0.9520\n",
      "Epoch 86/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9294 - val_loss: 0.1555 - val_accuracy: 0.9400\n",
      "Epoch 87/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9437 - val_loss: 0.1670 - val_accuracy: 0.9500\n",
      "Epoch 88/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9413 - val_loss: 0.1496 - val_accuracy: 0.9480\n",
      "Epoch 89/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1327 - accuracy: 0.9415 - val_loss: 0.1483 - val_accuracy: 0.9460\n",
      "Epoch 90/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9368 - val_loss: 0.1949 - val_accuracy: 0.9260\n",
      "Epoch 91/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9273 - val_loss: 0.1612 - val_accuracy: 0.9460\n",
      "Epoch 92/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9342 - val_loss: 0.1449 - val_accuracy: 0.9460\n",
      "Epoch 93/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1334 - accuracy: 0.9408 - val_loss: 0.1472 - val_accuracy: 0.9500\n",
      "Epoch 94/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1342 - accuracy: 0.9380 - val_loss: 0.1532 - val_accuracy: 0.9500\n",
      "Epoch 95/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1255 - accuracy: 0.9484 - val_loss: 0.1494 - val_accuracy: 0.9500\n",
      "Epoch 96/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1397 - accuracy: 0.9399 - val_loss: 0.1908 - val_accuracy: 0.9460\n",
      "Epoch 97/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9370 - val_loss: 0.1494 - val_accuracy: 0.9440\n",
      "Epoch 98/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1376 - accuracy: 0.9401 - val_loss: 0.1788 - val_accuracy: 0.9440\n",
      "Epoch 99/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1383 - accuracy: 0.9404 - val_loss: 0.1456 - val_accuracy: 0.9400\n",
      "Epoch 100/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1298 - accuracy: 0.9389 - val_loss: 0.1630 - val_accuracy: 0.9440\n",
      "Epoch 101/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9420 - val_loss: 0.1493 - val_accuracy: 0.9480\n",
      "Epoch 102/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1399 - accuracy: 0.9392 - val_loss: 0.1533 - val_accuracy: 0.9460\n",
      "Epoch 103/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1328 - accuracy: 0.9425 - val_loss: 0.1542 - val_accuracy: 0.9480\n",
      "Epoch 104/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1337 - accuracy: 0.9453 - val_loss: 0.1465 - val_accuracy: 0.9520\n",
      "Epoch 105/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1301 - accuracy: 0.9475 - val_loss: 0.1572 - val_accuracy: 0.9440\n",
      "Epoch 106/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9339 - val_loss: 0.1502 - val_accuracy: 0.9460\n",
      "Epoch 107/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1335 - accuracy: 0.9423 - val_loss: 0.1460 - val_accuracy: 0.9440\n",
      "Epoch 108/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1377 - accuracy: 0.9385 - val_loss: 0.1890 - val_accuracy: 0.9400\n",
      "Epoch 109/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9458 - val_loss: 0.1505 - val_accuracy: 0.9440\n",
      "Epoch 110/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1325 - accuracy: 0.9418 - val_loss: 0.1567 - val_accuracy: 0.9540\n",
      "Epoch 111/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1281 - accuracy: 0.9442 - val_loss: 0.1837 - val_accuracy: 0.9320\n",
      "Epoch 112/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1344 - accuracy: 0.9430 - val_loss: 0.1579 - val_accuracy: 0.9400\n",
      "Epoch 113/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1296 - accuracy: 0.9415 - val_loss: 0.1475 - val_accuracy: 0.9540\n",
      "Epoch 114/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1361 - accuracy: 0.9389 - val_loss: 0.1789 - val_accuracy: 0.9300\n",
      "Epoch 115/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1285 - accuracy: 0.9415 - val_loss: 0.1666 - val_accuracy: 0.9420\n",
      "Epoch 116/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1341 - accuracy: 0.9399 - val_loss: 0.1536 - val_accuracy: 0.9460\n",
      "Epoch 117/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1345 - accuracy: 0.9418 - val_loss: 0.2186 - val_accuracy: 0.9420\n",
      "Epoch 118/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1597 - accuracy: 0.9289 - val_loss: 0.1540 - val_accuracy: 0.9400\n",
      "Epoch 119/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9392 - val_loss: 0.1429 - val_accuracy: 0.9520\n",
      "Epoch 120/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1373 - accuracy: 0.9373 - val_loss: 0.1563 - val_accuracy: 0.9420\n",
      "Epoch 121/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1376 - accuracy: 0.9363 - val_loss: 0.1541 - val_accuracy: 0.9400\n",
      "Epoch 122/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1398 - accuracy: 0.9399 - val_loss: 0.1375 - val_accuracy: 0.9500\n",
      "Epoch 123/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9439 - val_loss: 0.1423 - val_accuracy: 0.9520\n",
      "Epoch 124/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1298 - accuracy: 0.9425 - val_loss: 0.1419 - val_accuracy: 0.9580\n",
      "Epoch 125/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1240 - accuracy: 0.9442 - val_loss: 0.1558 - val_accuracy: 0.9400\n",
      "Epoch 126/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1328 - accuracy: 0.9401 - val_loss: 0.1510 - val_accuracy: 0.9500\n",
      "Epoch 127/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1323 - accuracy: 0.9406 - val_loss: 0.1413 - val_accuracy: 0.9500\n",
      "Epoch 128/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1287 - accuracy: 0.9437 - val_loss: 0.1471 - val_accuracy: 0.9420\n",
      "Epoch 129/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1395 - accuracy: 0.9337 - val_loss: 0.1506 - val_accuracy: 0.9520\n",
      "Epoch 130/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1296 - accuracy: 0.9427 - val_loss: 0.1592 - val_accuracy: 0.9440\n",
      "Epoch 131/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1319 - accuracy: 0.9477 - val_loss: 0.1716 - val_accuracy: 0.9360\n",
      "Epoch 132/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1306 - accuracy: 0.9387 - val_loss: 0.2128 - val_accuracy: 0.9420\n",
      "Epoch 133/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1419 - accuracy: 0.9377 - val_loss: 0.1421 - val_accuracy: 0.9440\n",
      "Epoch 134/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1778 - accuracy: 0.9116 - val_loss: 0.1541 - val_accuracy: 0.9580\n",
      "Epoch 135/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1336 - accuracy: 0.9408 - val_loss: 0.1451 - val_accuracy: 0.9520\n",
      "Epoch 136/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1349 - accuracy: 0.9351 - val_loss: 0.1502 - val_accuracy: 0.9440\n",
      "Epoch 137/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1207 - accuracy: 0.9425 - val_loss: 0.1574 - val_accuracy: 0.9440\n",
      "Epoch 138/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1314 - accuracy: 0.9406 - val_loss: 0.1484 - val_accuracy: 0.9580\n",
      "Epoch 139/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1324 - accuracy: 0.9439 - val_loss: 0.1496 - val_accuracy: 0.9460\n",
      "Epoch 140/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1393 - accuracy: 0.9368 - val_loss: 0.1446 - val_accuracy: 0.9500\n",
      "Epoch 141/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1378 - accuracy: 0.9406 - val_loss: 0.1431 - val_accuracy: 0.9520\n",
      "Epoch 142/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1263 - accuracy: 0.9468 - val_loss: 0.1630 - val_accuracy: 0.9480\n",
      "Epoch 143/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1266 - accuracy: 0.9437 - val_loss: 0.1429 - val_accuracy: 0.9460\n",
      "Epoch 144/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1200 - accuracy: 0.9475 - val_loss: 0.1483 - val_accuracy: 0.9540\n",
      "Epoch 145/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1295 - accuracy: 0.9418 - val_loss: 0.1548 - val_accuracy: 0.9440\n",
      "Epoch 146/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1195 - accuracy: 0.9475 - val_loss: 0.1496 - val_accuracy: 0.9460\n",
      "Epoch 147/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9477 - val_loss: 0.1517 - val_accuracy: 0.9520\n",
      "Epoch 148/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1254 - accuracy: 0.9442 - val_loss: 0.1695 - val_accuracy: 0.9420\n",
      "Epoch 149/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1371 - accuracy: 0.9385 - val_loss: 0.1491 - val_accuracy: 0.9360\n",
      "Epoch 150/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9363 - val_loss: 0.1483 - val_accuracy: 0.9540\n",
      "Epoch 151/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1267 - accuracy: 0.9444 - val_loss: 0.1476 - val_accuracy: 0.9540\n",
      "Epoch 152/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1314 - accuracy: 0.9434 - val_loss: 0.1434 - val_accuracy: 0.9540\n",
      "Epoch 153/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1280 - accuracy: 0.9432 - val_loss: 0.1583 - val_accuracy: 0.9520\n",
      "Epoch 154/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1285 - accuracy: 0.9439 - val_loss: 0.1403 - val_accuracy: 0.9500\n",
      "Epoch 155/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1321 - accuracy: 0.9392 - val_loss: 0.1866 - val_accuracy: 0.9480\n",
      "Epoch 156/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1357 - accuracy: 0.9380 - val_loss: 0.1548 - val_accuracy: 0.9380\n",
      "Epoch 157/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9439 - val_loss: 0.1433 - val_accuracy: 0.9500\n",
      "Epoch 158/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1250 - accuracy: 0.9468 - val_loss: 0.1654 - val_accuracy: 0.9460\n",
      "Epoch 159/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1226 - accuracy: 0.9461 - val_loss: 0.1497 - val_accuracy: 0.9540\n",
      "Epoch 160/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1276 - accuracy: 0.9427 - val_loss: 0.1483 - val_accuracy: 0.9520\n",
      "Epoch 161/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9335 - val_loss: 0.1395 - val_accuracy: 0.9540\n",
      "Epoch 162/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9415 - val_loss: 0.1661 - val_accuracy: 0.9540\n",
      "Epoch 163/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1529 - accuracy: 0.9365 - val_loss: 0.1605 - val_accuracy: 0.9320\n",
      "Epoch 164/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1279 - accuracy: 0.9399 - val_loss: 0.1483 - val_accuracy: 0.9580\n",
      "Epoch 165/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9349 - val_loss: 0.1737 - val_accuracy: 0.9380\n",
      "Epoch 166/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1227 - accuracy: 0.9465 - val_loss: 0.1403 - val_accuracy: 0.9520\n",
      "Epoch 167/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1307 - accuracy: 0.9434 - val_loss: 0.2092 - val_accuracy: 0.9340\n",
      "Epoch 168/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1207 - accuracy: 0.9453 - val_loss: 0.1864 - val_accuracy: 0.9320\n",
      "Epoch 169/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1386 - accuracy: 0.9335 - val_loss: 0.1393 - val_accuracy: 0.9540\n",
      "Epoch 170/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1239 - accuracy: 0.9468 - val_loss: 0.1477 - val_accuracy: 0.9600\n",
      "Epoch 171/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1217 - accuracy: 0.9475 - val_loss: 0.1437 - val_accuracy: 0.9360\n",
      "Epoch 172/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1238 - accuracy: 0.9491 - val_loss: 0.1505 - val_accuracy: 0.9560\n",
      "Epoch 173/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1215 - accuracy: 0.9499 - val_loss: 0.1458 - val_accuracy: 0.9500\n",
      "Epoch 174/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1222 - accuracy: 0.9470 - val_loss: 0.1417 - val_accuracy: 0.9540\n",
      "Epoch 175/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1260 - accuracy: 0.9453 - val_loss: 0.1453 - val_accuracy: 0.9360\n",
      "Epoch 176/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1572 - accuracy: 0.9308 - val_loss: 0.1551 - val_accuracy: 0.9420\n",
      "Epoch 177/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9406 - val_loss: 0.1625 - val_accuracy: 0.9440\n",
      "Epoch 178/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1359 - accuracy: 0.9406 - val_loss: 0.1560 - val_accuracy: 0.9460\n",
      "Epoch 179/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1229 - accuracy: 0.9453 - val_loss: 0.1561 - val_accuracy: 0.9460\n",
      "Epoch 180/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1313 - accuracy: 0.9382 - val_loss: 0.1573 - val_accuracy: 0.9500\n",
      "Epoch 181/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1254 - accuracy: 0.9444 - val_loss: 0.1504 - val_accuracy: 0.9560\n",
      "Epoch 182/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1228 - accuracy: 0.9461 - val_loss: 0.1401 - val_accuracy: 0.9480\n",
      "Epoch 183/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1221 - accuracy: 0.9480 - val_loss: 0.1457 - val_accuracy: 0.9540\n",
      "Epoch 184/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9430 - val_loss: 0.1651 - val_accuracy: 0.9520\n",
      "Epoch 185/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1178 - accuracy: 0.9468 - val_loss: 0.1443 - val_accuracy: 0.9520\n",
      "Epoch 186/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1157 - accuracy: 0.9491 - val_loss: 0.1565 - val_accuracy: 0.9520\n",
      "Epoch 187/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1273 - accuracy: 0.9356 - val_loss: 0.1471 - val_accuracy: 0.9440\n",
      "Epoch 188/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9320 - val_loss: 0.1495 - val_accuracy: 0.9400\n",
      "Epoch 189/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9427 - val_loss: 0.1639 - val_accuracy: 0.9460\n",
      "Epoch 190/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1131 - accuracy: 0.9525 - val_loss: 0.1483 - val_accuracy: 0.9380\n",
      "Epoch 191/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1321 - accuracy: 0.9446 - val_loss: 0.1439 - val_accuracy: 0.9560\n",
      "Epoch 192/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1253 - accuracy: 0.9430 - val_loss: 0.1513 - val_accuracy: 0.9480\n",
      "Epoch 193/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1419 - accuracy: 0.9411 - val_loss: 0.1395 - val_accuracy: 0.9520\n",
      "Epoch 194/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1249 - accuracy: 0.9439 - val_loss: 0.1455 - val_accuracy: 0.9480\n",
      "Epoch 195/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1206 - accuracy: 0.9463 - val_loss: 0.1642 - val_accuracy: 0.9480\n",
      "Epoch 196/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1298 - accuracy: 0.9458 - val_loss: 0.1489 - val_accuracy: 0.9500\n",
      "Epoch 197/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1235 - accuracy: 0.9437 - val_loss: 0.1626 - val_accuracy: 0.9400\n",
      "Epoch 198/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1169 - accuracy: 0.9487 - val_loss: 0.1863 - val_accuracy: 0.9500\n",
      "Epoch 199/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1242 - accuracy: 0.9442 - val_loss: 0.1899 - val_accuracy: 0.9480\n",
      "Epoch 200/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9487 - val_loss: 0.1390 - val_accuracy: 0.9540\n",
      "Epoch 201/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1132 - accuracy: 0.9468 - val_loss: 0.1396 - val_accuracy: 0.9520\n",
      "Epoch 202/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1216 - accuracy: 0.9434 - val_loss: 0.1534 - val_accuracy: 0.9520\n",
      "Epoch 203/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1252 - accuracy: 0.9413 - val_loss: 0.1658 - val_accuracy: 0.9500\n",
      "Epoch 204/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1369 - accuracy: 0.9387 - val_loss: 0.1363 - val_accuracy: 0.9480\n",
      "Epoch 205/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1172 - accuracy: 0.9425 - val_loss: 0.1366 - val_accuracy: 0.9520\n",
      "Epoch 206/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9342 - val_loss: 0.1430 - val_accuracy: 0.9540\n",
      "Epoch 207/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1197 - accuracy: 0.9451 - val_loss: 0.1399 - val_accuracy: 0.9400\n",
      "Epoch 208/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1104 - accuracy: 0.9461 - val_loss: 0.1453 - val_accuracy: 0.9560\n",
      "Epoch 209/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1165 - accuracy: 0.9522 - val_loss: 0.1425 - val_accuracy: 0.9420\n",
      "Epoch 210/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1315 - accuracy: 0.9399 - val_loss: 0.1467 - val_accuracy: 0.9500\n",
      "Epoch 211/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1251 - accuracy: 0.9425 - val_loss: 0.1450 - val_accuracy: 0.9560\n",
      "Epoch 212/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1192 - accuracy: 0.9451 - val_loss: 0.1431 - val_accuracy: 0.9540\n",
      "Epoch 213/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9451 - val_loss: 0.1355 - val_accuracy: 0.9520\n",
      "Epoch 214/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9442 - val_loss: 0.1396 - val_accuracy: 0.9440\n",
      "Epoch 215/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1203 - accuracy: 0.9472 - val_loss: 0.1683 - val_accuracy: 0.9360\n",
      "Epoch 216/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1298 - accuracy: 0.9418 - val_loss: 0.1428 - val_accuracy: 0.9480\n",
      "Epoch 217/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1129 - accuracy: 0.9496 - val_loss: 0.1604 - val_accuracy: 0.9560\n",
      "Epoch 218/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1342 - accuracy: 0.9387 - val_loss: 0.1565 - val_accuracy: 0.9480\n",
      "Epoch 219/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1106 - accuracy: 0.9515 - val_loss: 0.1768 - val_accuracy: 0.9360\n",
      "Epoch 220/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1231 - accuracy: 0.9427 - val_loss: 0.1494 - val_accuracy: 0.9380\n",
      "Epoch 221/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1191 - accuracy: 0.9461 - val_loss: 0.1417 - val_accuracy: 0.9440\n",
      "Epoch 222/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1209 - accuracy: 0.9444 - val_loss: 0.1543 - val_accuracy: 0.9360\n",
      "Epoch 223/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1130 - accuracy: 0.9515 - val_loss: 0.1489 - val_accuracy: 0.9480\n",
      "Epoch 224/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1192 - accuracy: 0.9442 - val_loss: 0.1695 - val_accuracy: 0.9360\n",
      "Epoch 225/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1142 - accuracy: 0.9465 - val_loss: 0.1628 - val_accuracy: 0.9500\n",
      "Epoch 226/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1401 - accuracy: 0.9365 - val_loss: 0.1420 - val_accuracy: 0.9540\n",
      "Epoch 227/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1386 - accuracy: 0.9411 - val_loss: 0.1452 - val_accuracy: 0.9480\n",
      "Epoch 228/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1700 - accuracy: 0.9204 - val_loss: 0.1845 - val_accuracy: 0.9380\n",
      "Epoch 229/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1301 - accuracy: 0.9439 - val_loss: 0.1651 - val_accuracy: 0.9440\n",
      "Epoch 230/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1107 - accuracy: 0.9510 - val_loss: 0.1512 - val_accuracy: 0.9540\n",
      "Epoch 231/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1160 - accuracy: 0.9477 - val_loss: 0.1407 - val_accuracy: 0.9460\n",
      "Epoch 232/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1127 - accuracy: 0.9470 - val_loss: 0.1474 - val_accuracy: 0.9440\n",
      "Epoch 233/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1229 - accuracy: 0.9463 - val_loss: 0.1605 - val_accuracy: 0.9480\n",
      "Epoch 234/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1204 - accuracy: 0.9465 - val_loss: 0.1599 - val_accuracy: 0.9580\n",
      "Epoch 235/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1198 - accuracy: 0.9503 - val_loss: 0.1508 - val_accuracy: 0.9480\n",
      "Epoch 236/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1210 - accuracy: 0.9442 - val_loss: 0.1490 - val_accuracy: 0.9480\n",
      "Epoch 237/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1194 - accuracy: 0.9458 - val_loss: 0.1356 - val_accuracy: 0.9520\n",
      "Epoch 238/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1141 - accuracy: 0.9496 - val_loss: 0.1459 - val_accuracy: 0.9500\n",
      "Epoch 239/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1101 - accuracy: 0.9439 - val_loss: 0.1517 - val_accuracy: 0.9600\n",
      "Epoch 240/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1221 - accuracy: 0.9475 - val_loss: 0.1543 - val_accuracy: 0.9360\n",
      "Epoch 241/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1205 - accuracy: 0.9484 - val_loss: 0.1613 - val_accuracy: 0.9380\n",
      "Epoch 242/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1418 - accuracy: 0.9394 - val_loss: 0.1454 - val_accuracy: 0.9540\n",
      "Epoch 243/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1215 - accuracy: 0.9453 - val_loss: 0.1333 - val_accuracy: 0.9520\n",
      "Epoch 244/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1112 - accuracy: 0.9487 - val_loss: 0.1643 - val_accuracy: 0.9440\n",
      "Epoch 245/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1172 - accuracy: 0.9444 - val_loss: 0.1555 - val_accuracy: 0.9520\n",
      "Epoch 246/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1072 - accuracy: 0.9522 - val_loss: 0.1628 - val_accuracy: 0.9600\n",
      "Epoch 247/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1297 - accuracy: 0.9442 - val_loss: 0.1430 - val_accuracy: 0.9560\n",
      "Epoch 248/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9408 - val_loss: 0.1442 - val_accuracy: 0.9400\n",
      "Epoch 249/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1279 - accuracy: 0.9406 - val_loss: 0.1407 - val_accuracy: 0.9500\n",
      "Epoch 250/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1192 - accuracy: 0.9503 - val_loss: 0.1378 - val_accuracy: 0.9500\n",
      "Epoch 251/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1225 - accuracy: 0.9399 - val_loss: 0.1406 - val_accuracy: 0.9560\n",
      "Epoch 252/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1138 - accuracy: 0.9503 - val_loss: 0.1435 - val_accuracy: 0.9600\n",
      "Epoch 253/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1032 - accuracy: 0.9527 - val_loss: 0.1468 - val_accuracy: 0.9620\n",
      "Epoch 254/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1099 - accuracy: 0.9484 - val_loss: 0.1433 - val_accuracy: 0.9540\n",
      "Epoch 255/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1189 - accuracy: 0.9461 - val_loss: 0.1436 - val_accuracy: 0.9540\n",
      "Epoch 256/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1280 - accuracy: 0.9413 - val_loss: 0.1419 - val_accuracy: 0.9480\n",
      "Epoch 257/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1194 - accuracy: 0.9432 - val_loss: 0.1496 - val_accuracy: 0.9520\n",
      "Epoch 258/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1180 - accuracy: 0.9463 - val_loss: 0.1493 - val_accuracy: 0.9600\n",
      "Epoch 259/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1340 - accuracy: 0.9373 - val_loss: 0.1405 - val_accuracy: 0.9440\n",
      "Epoch 260/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1273 - accuracy: 0.9442 - val_loss: 0.1845 - val_accuracy: 0.9360\n",
      "Epoch 261/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1110 - accuracy: 0.9432 - val_loss: 0.1432 - val_accuracy: 0.9440\n",
      "Epoch 262/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1238 - accuracy: 0.9439 - val_loss: 0.1502 - val_accuracy: 0.9440\n",
      "Epoch 263/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1047 - accuracy: 0.9503 - val_loss: 0.1347 - val_accuracy: 0.9560\n",
      "Epoch 264/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1123 - accuracy: 0.9496 - val_loss: 0.1376 - val_accuracy: 0.9560\n",
      "Epoch 265/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1307 - accuracy: 0.9396 - val_loss: 0.1454 - val_accuracy: 0.9540\n",
      "Epoch 266/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1028 - accuracy: 0.9556 - val_loss: 0.1395 - val_accuracy: 0.9540\n",
      "Epoch 267/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1131 - accuracy: 0.9465 - val_loss: 0.1324 - val_accuracy: 0.9580\n",
      "Epoch 268/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1154 - accuracy: 0.9456 - val_loss: 0.1758 - val_accuracy: 0.9220\n",
      "Epoch 269/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1300 - accuracy: 0.9380 - val_loss: 0.1990 - val_accuracy: 0.9140\n",
      "Epoch 270/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1205 - accuracy: 0.9458 - val_loss: 0.1991 - val_accuracy: 0.9540\n",
      "Epoch 271/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1150 - accuracy: 0.9506 - val_loss: 0.1420 - val_accuracy: 0.9500\n",
      "Epoch 272/500\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.1338 - accuracy: 0.9444 - val_loss: 0.1332 - val_accuracy: 0.9580\n",
      "Epoch 273/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1151 - accuracy: 0.9499 - val_loss: 0.1480 - val_accuracy: 0.9580\n",
      "Epoch 274/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1053 - accuracy: 0.9518 - val_loss: 0.1565 - val_accuracy: 0.9560\n",
      "Epoch 275/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1112 - accuracy: 0.9515 - val_loss: 0.1751 - val_accuracy: 0.9540\n",
      "Epoch 276/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1355 - accuracy: 0.9430 - val_loss: 0.1373 - val_accuracy: 0.9500\n",
      "Epoch 277/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1263 - accuracy: 0.9482 - val_loss: 0.1514 - val_accuracy: 0.9340\n",
      "Epoch 278/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1380 - accuracy: 0.9468 - val_loss: 0.1416 - val_accuracy: 0.9460\n",
      "Epoch 279/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1408 - accuracy: 0.9444 - val_loss: 0.1433 - val_accuracy: 0.9480\n",
      "Epoch 280/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9415 - val_loss: 0.2081 - val_accuracy: 0.9360\n",
      "Epoch 281/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1374 - accuracy: 0.9408 - val_loss: 0.1889 - val_accuracy: 0.9440\n",
      "Epoch 282/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1240 - accuracy: 0.9501 - val_loss: 0.1554 - val_accuracy: 0.9460\n",
      "Epoch 283/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1655 - accuracy: 0.9211 - val_loss: 0.1777 - val_accuracy: 0.9400\n",
      "Epoch 284/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1355 - accuracy: 0.9487 - val_loss: 0.1714 - val_accuracy: 0.9420\n",
      "Epoch 285/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1272 - accuracy: 0.9420 - val_loss: 0.1375 - val_accuracy: 0.9500\n",
      "Epoch 286/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1140 - accuracy: 0.9551 - val_loss: 0.1860 - val_accuracy: 0.9500\n",
      "Epoch 287/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1636 - accuracy: 0.9316 - val_loss: 0.1763 - val_accuracy: 0.9420\n",
      "Epoch 288/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1197 - accuracy: 0.9506 - val_loss: 0.1397 - val_accuracy: 0.9500\n",
      "Epoch 289/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9415 - val_loss: 0.1423 - val_accuracy: 0.9480\n",
      "Epoch 290/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1307 - accuracy: 0.9446 - val_loss: 0.1354 - val_accuracy: 0.9540\n",
      "Epoch 291/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9499 - val_loss: 0.1467 - val_accuracy: 0.9540\n",
      "Epoch 292/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1112 - accuracy: 0.9496 - val_loss: 0.1686 - val_accuracy: 0.9460\n",
      "Epoch 293/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1074 - accuracy: 0.9463 - val_loss: 0.1459 - val_accuracy: 0.9500\n",
      "Epoch 294/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1134 - accuracy: 0.9425 - val_loss: 0.1411 - val_accuracy: 0.9540\n",
      "Epoch 295/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1220 - accuracy: 0.9456 - val_loss: 0.1428 - val_accuracy: 0.9560\n",
      "Epoch 296/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1258 - accuracy: 0.9513 - val_loss: 0.1636 - val_accuracy: 0.9440\n",
      "Epoch 297/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1330 - accuracy: 0.9458 - val_loss: 0.1626 - val_accuracy: 0.9480\n",
      "Epoch 298/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1364 - accuracy: 0.9430 - val_loss: 0.1569 - val_accuracy: 0.9420\n",
      "Epoch 299/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1208 - accuracy: 0.9482 - val_loss: 0.1545 - val_accuracy: 0.9580\n",
      "Epoch 300/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1057 - accuracy: 0.9537 - val_loss: 0.1759 - val_accuracy: 0.9580\n",
      "Epoch 301/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1136 - accuracy: 0.9515 - val_loss: 0.1516 - val_accuracy: 0.9480\n",
      "Epoch 302/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1406 - accuracy: 0.9339 - val_loss: 0.1440 - val_accuracy: 0.9520\n",
      "Epoch 303/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1307 - accuracy: 0.9446 - val_loss: 0.1933 - val_accuracy: 0.9440\n",
      "Epoch 304/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1398 - accuracy: 0.9399 - val_loss: 0.1489 - val_accuracy: 0.9460\n",
      "Epoch 305/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1216 - accuracy: 0.9520 - val_loss: 0.1574 - val_accuracy: 0.9520\n",
      "Epoch 306/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9458 - val_loss: 0.1976 - val_accuracy: 0.9420\n",
      "Epoch 307/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1230 - accuracy: 0.9494 - val_loss: 0.1924 - val_accuracy: 0.9480\n",
      "Epoch 308/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1239 - accuracy: 0.9496 - val_loss: 0.1524 - val_accuracy: 0.9540\n",
      "Epoch 309/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1146 - accuracy: 0.9477 - val_loss: 0.1606 - val_accuracy: 0.9440\n",
      "Epoch 310/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1124 - accuracy: 0.9494 - val_loss: 0.1612 - val_accuracy: 0.9480\n",
      "Epoch 311/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1104 - accuracy: 0.9534 - val_loss: 0.1568 - val_accuracy: 0.9500\n",
      "Epoch 312/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1096 - accuracy: 0.9520 - val_loss: 0.1411 - val_accuracy: 0.9540\n",
      "Epoch 313/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1259 - accuracy: 0.9406 - val_loss: 0.2031 - val_accuracy: 0.9240\n",
      "Epoch 314/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1220 - accuracy: 0.9401 - val_loss: 0.1408 - val_accuracy: 0.9580\n",
      "Epoch 315/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0993 - accuracy: 0.9503 - val_loss: 0.1443 - val_accuracy: 0.9580\n",
      "Epoch 316/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1077 - accuracy: 0.9537 - val_loss: 0.1357 - val_accuracy: 0.9540\n",
      "Epoch 317/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1160 - accuracy: 0.9472 - val_loss: 0.1715 - val_accuracy: 0.9480\n",
      "Epoch 318/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1077 - accuracy: 0.9558 - val_loss: 0.1374 - val_accuracy: 0.9560\n",
      "Epoch 319/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1142 - accuracy: 0.9475 - val_loss: 0.1590 - val_accuracy: 0.9540\n",
      "Epoch 320/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1045 - accuracy: 0.9515 - val_loss: 0.1636 - val_accuracy: 0.9580\n",
      "Epoch 321/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1309 - accuracy: 0.9468 - val_loss: 0.2528 - val_accuracy: 0.9380\n",
      "Epoch 322/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1209 - accuracy: 0.9484 - val_loss: 0.2257 - val_accuracy: 0.9440\n",
      "Epoch 323/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1209 - accuracy: 0.9529 - val_loss: 0.1552 - val_accuracy: 0.9500\n",
      "Epoch 324/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1222 - accuracy: 0.9463 - val_loss: 0.1450 - val_accuracy: 0.9600\n",
      "Epoch 325/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9527 - val_loss: 0.1800 - val_accuracy: 0.9540\n",
      "Epoch 326/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1194 - accuracy: 0.9518 - val_loss: 0.1421 - val_accuracy: 0.9500\n",
      "Epoch 327/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1119 - accuracy: 0.9482 - val_loss: 0.1515 - val_accuracy: 0.9460\n",
      "Epoch 328/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1177 - accuracy: 0.9496 - val_loss: 0.1424 - val_accuracy: 0.9540\n",
      "Epoch 329/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1123 - accuracy: 0.9453 - val_loss: 0.1478 - val_accuracy: 0.9540\n",
      "Epoch 330/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1018 - accuracy: 0.9548 - val_loss: 0.1611 - val_accuracy: 0.9440\n",
      "Epoch 331/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1180 - accuracy: 0.9461 - val_loss: 0.1998 - val_accuracy: 0.9360\n",
      "Epoch 332/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1095 - accuracy: 0.9513 - val_loss: 0.1580 - val_accuracy: 0.9460\n",
      "Epoch 333/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9496 - val_loss: 0.2172 - val_accuracy: 0.9320\n",
      "Epoch 334/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1197 - accuracy: 0.9499 - val_loss: 0.1382 - val_accuracy: 0.9540\n",
      "Epoch 335/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1160 - accuracy: 0.9513 - val_loss: 0.1399 - val_accuracy: 0.9460\n",
      "Epoch 336/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1042 - accuracy: 0.9548 - val_loss: 0.1426 - val_accuracy: 0.9440\n",
      "Epoch 337/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1129 - accuracy: 0.9449 - val_loss: 0.1482 - val_accuracy: 0.9560\n",
      "Epoch 338/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9525 - val_loss: 0.1393 - val_accuracy: 0.9540\n",
      "Epoch 339/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1099 - accuracy: 0.9489 - val_loss: 0.1424 - val_accuracy: 0.9520\n",
      "Epoch 340/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1388 - accuracy: 0.9387 - val_loss: 0.1673 - val_accuracy: 0.9460\n",
      "Epoch 341/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1136 - accuracy: 0.9458 - val_loss: 0.1340 - val_accuracy: 0.9540\n",
      "Epoch 342/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1091 - accuracy: 0.9475 - val_loss: 0.1898 - val_accuracy: 0.9620\n",
      "Epoch 343/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1127 - accuracy: 0.9522 - val_loss: 0.1504 - val_accuracy: 0.9560\n",
      "Epoch 344/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9487 - val_loss: 0.1552 - val_accuracy: 0.9520\n",
      "Epoch 345/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1196 - accuracy: 0.9482 - val_loss: 0.1423 - val_accuracy: 0.9560\n",
      "Epoch 346/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1127 - accuracy: 0.9477 - val_loss: 0.1416 - val_accuracy: 0.9520\n",
      "Epoch 347/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9494 - val_loss: 0.1609 - val_accuracy: 0.9480\n",
      "Epoch 348/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1063 - accuracy: 0.9489 - val_loss: 0.1523 - val_accuracy: 0.9520\n",
      "Epoch 349/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1187 - accuracy: 0.9449 - val_loss: 0.1540 - val_accuracy: 0.9460\n",
      "Epoch 350/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1069 - accuracy: 0.9501 - val_loss: 0.1453 - val_accuracy: 0.9580\n",
      "Epoch 351/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1091 - accuracy: 0.9489 - val_loss: 0.1726 - val_accuracy: 0.9540\n",
      "Epoch 352/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1040 - accuracy: 0.9494 - val_loss: 0.1770 - val_accuracy: 0.9440\n",
      "Epoch 353/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1061 - accuracy: 0.9489 - val_loss: 0.1563 - val_accuracy: 0.9520\n",
      "\n",
      "\n",
      "\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1005 - accuracy: 0.9637\n"
     ]
    }
   ],
   "source": [
    "def build_fnn_drop_model(dropout):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "\n",
    "    model.add(keras.layers.Dense(512, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_fnn_drop_model(model):\n",
    "    model.fit(x_train_images, x_train_labels, epochs=500,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_valid_images, x_valid_labels),\n",
    "                    callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=100)])\n",
    "\n",
    "fnn_drop = build_fnn_drop_model(0.25)\n",
    "train_fnn_drop_model(fnn_drop)\n",
    "print(\"\\n\\n\")\n",
    "cur_loss, cur_acc = fnn_drop.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un ultimo approccio con le reti FNN si basa sul sfruttare la struttura di un autoencoder, ovvero si usa una struttura simmetrica per i primi livelli, con numero di unità che decrescono e poi ricrescono simmetricamente. Questa idea è stata presa da un altro corso e testata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.3480 - accuracy: 0.8527 - val_loss: 0.4512 - val_accuracy: 0.8520\n",
      "Epoch 2/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1973 - accuracy: 0.9247 - val_loss: 0.5114 - val_accuracy: 0.7820\n",
      "Epoch 3/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2110 - accuracy: 0.9266 - val_loss: 0.1783 - val_accuracy: 0.9280\n",
      "Epoch 4/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1733 - accuracy: 0.9344 - val_loss: 0.2069 - val_accuracy: 0.9140\n",
      "Epoch 5/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1572 - accuracy: 0.9385 - val_loss: 0.2960 - val_accuracy: 0.8840\n",
      "Epoch 6/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 0.9377 - val_loss: 0.1644 - val_accuracy: 0.9300\n",
      "Epoch 7/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1526 - accuracy: 0.9408 - val_loss: 0.1737 - val_accuracy: 0.9320\n",
      "Epoch 8/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1537 - accuracy: 0.9415 - val_loss: 0.2169 - val_accuracy: 0.9340\n",
      "Epoch 9/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1594 - accuracy: 0.9368 - val_loss: 0.1639 - val_accuracy: 0.9340\n",
      "Epoch 10/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.9472 - val_loss: 0.1739 - val_accuracy: 0.9300\n",
      "Epoch 11/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1383 - accuracy: 0.9472 - val_loss: 0.1938 - val_accuracy: 0.9180\n",
      "Epoch 12/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1528 - accuracy: 0.9387 - val_loss: 0.1775 - val_accuracy: 0.9400\n",
      "Epoch 13/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9437 - val_loss: 0.1719 - val_accuracy: 0.9340\n",
      "Epoch 14/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1407 - accuracy: 0.9456 - val_loss: 0.1659 - val_accuracy: 0.9400\n",
      "Epoch 15/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1378 - accuracy: 0.9458 - val_loss: 0.1582 - val_accuracy: 0.9420\n",
      "Epoch 16/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1333 - accuracy: 0.9468 - val_loss: 0.2362 - val_accuracy: 0.9340\n",
      "Epoch 17/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1461 - accuracy: 0.9444 - val_loss: 0.2310 - val_accuracy: 0.8980\n",
      "Epoch 18/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1330 - accuracy: 0.9510 - val_loss: 0.1505 - val_accuracy: 0.9440\n",
      "Epoch 19/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1347 - accuracy: 0.9477 - val_loss: 0.1580 - val_accuracy: 0.9320\n",
      "Epoch 20/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1358 - accuracy: 0.9470 - val_loss: 0.4463 - val_accuracy: 0.8340\n",
      "Epoch 21/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1666 - accuracy: 0.9380 - val_loss: 0.1735 - val_accuracy: 0.9300\n",
      "Epoch 22/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1285 - accuracy: 0.9503 - val_loss: 0.2159 - val_accuracy: 0.9220\n",
      "Epoch 23/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1330 - accuracy: 0.9487 - val_loss: 0.1567 - val_accuracy: 0.9440\n",
      "Epoch 24/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9494 - val_loss: 0.1505 - val_accuracy: 0.9460\n",
      "Epoch 25/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1311 - accuracy: 0.9513 - val_loss: 0.1549 - val_accuracy: 0.9420\n",
      "Epoch 26/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1207 - accuracy: 0.9529 - val_loss: 0.1544 - val_accuracy: 0.9460\n",
      "Epoch 27/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1205 - accuracy: 0.9515 - val_loss: 0.1924 - val_accuracy: 0.9140\n",
      "Epoch 28/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1346 - accuracy: 0.9468 - val_loss: 0.1482 - val_accuracy: 0.9440\n",
      "Epoch 29/500\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.1175 - accuracy: 0.9522 - val_loss: 0.1901 - val_accuracy: 0.9320\n",
      "Epoch 30/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1141 - accuracy: 0.9520 - val_loss: 0.1580 - val_accuracy: 0.9480\n",
      "Epoch 31/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1424 - accuracy: 0.9461 - val_loss: 0.1562 - val_accuracy: 0.9480\n",
      "Epoch 32/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1267 - accuracy: 0.9513 - val_loss: 0.1492 - val_accuracy: 0.9460\n",
      "Epoch 33/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1116 - accuracy: 0.9563 - val_loss: 0.1593 - val_accuracy: 0.9440\n",
      "Epoch 34/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1302 - accuracy: 0.9491 - val_loss: 0.1984 - val_accuracy: 0.9100\n",
      "Epoch 35/500\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.1588 - accuracy: 0.9432 - val_loss: 0.2045 - val_accuracy: 0.9300\n",
      "Epoch 36/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1270 - accuracy: 0.9489 - val_loss: 0.1653 - val_accuracy: 0.9320\n",
      "Epoch 37/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1165 - accuracy: 0.9541 - val_loss: 0.1777 - val_accuracy: 0.9260\n",
      "Epoch 38/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1230 - accuracy: 0.9484 - val_loss: 0.1496 - val_accuracy: 0.9460\n",
      "Epoch 39/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1222 - accuracy: 0.9494 - val_loss: 0.2331 - val_accuracy: 0.9360\n",
      "Epoch 40/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1122 - accuracy: 0.9567 - val_loss: 0.1440 - val_accuracy: 0.9460\n",
      "Epoch 41/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1227 - accuracy: 0.9525 - val_loss: 0.2073 - val_accuracy: 0.9300\n",
      "Epoch 42/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9539 - val_loss: 0.1664 - val_accuracy: 0.9480\n",
      "Epoch 43/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1162 - accuracy: 0.9546 - val_loss: 0.1605 - val_accuracy: 0.9320\n",
      "Epoch 44/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9525 - val_loss: 0.1995 - val_accuracy: 0.9360\n",
      "Epoch 45/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1066 - accuracy: 0.9579 - val_loss: 0.1574 - val_accuracy: 0.9500\n",
      "Epoch 46/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1134 - accuracy: 0.9548 - val_loss: 0.1625 - val_accuracy: 0.9500\n",
      "Epoch 47/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1400 - accuracy: 0.9496 - val_loss: 0.1446 - val_accuracy: 0.9420\n",
      "Epoch 48/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1266 - accuracy: 0.9501 - val_loss: 0.2580 - val_accuracy: 0.9200\n",
      "Epoch 49/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1163 - accuracy: 0.9594 - val_loss: 0.1522 - val_accuracy: 0.9500\n",
      "Epoch 50/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1082 - accuracy: 0.9608 - val_loss: 0.1484 - val_accuracy: 0.9520\n",
      "Epoch 51/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1174 - accuracy: 0.9518 - val_loss: 0.2025 - val_accuracy: 0.9420\n",
      "Epoch 52/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1046 - accuracy: 0.9613 - val_loss: 0.1618 - val_accuracy: 0.9500\n",
      "Epoch 53/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1027 - accuracy: 0.9622 - val_loss: 0.1532 - val_accuracy: 0.9520\n",
      "Epoch 54/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1091 - accuracy: 0.9572 - val_loss: 0.1786 - val_accuracy: 0.9500\n",
      "Epoch 55/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1108 - accuracy: 0.9553 - val_loss: 0.1783 - val_accuracy: 0.9380\n",
      "Epoch 56/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1111 - accuracy: 0.9594 - val_loss: 0.1694 - val_accuracy: 0.9480\n",
      "Epoch 57/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1023 - accuracy: 0.9608 - val_loss: 0.2294 - val_accuracy: 0.9400\n",
      "Epoch 58/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0976 - accuracy: 0.9615 - val_loss: 0.2445 - val_accuracy: 0.9340\n",
      "Epoch 59/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1174 - accuracy: 0.9525 - val_loss: 0.1530 - val_accuracy: 0.9560\n",
      "Epoch 60/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1053 - accuracy: 0.9613 - val_loss: 0.1496 - val_accuracy: 0.9560\n",
      "Epoch 61/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1097 - accuracy: 0.9544 - val_loss: 0.1625 - val_accuracy: 0.9320\n",
      "Epoch 62/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1103 - accuracy: 0.9582 - val_loss: 0.1742 - val_accuracy: 0.9420\n",
      "Epoch 63/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0969 - accuracy: 0.9627 - val_loss: 0.1472 - val_accuracy: 0.9580\n",
      "Epoch 64/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0933 - accuracy: 0.9622 - val_loss: 0.1817 - val_accuracy: 0.9280\n",
      "Epoch 65/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1148 - accuracy: 0.9570 - val_loss: 0.1455 - val_accuracy: 0.9560\n",
      "Epoch 66/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0928 - accuracy: 0.9651 - val_loss: 0.2941 - val_accuracy: 0.9420\n",
      "Epoch 67/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1124 - accuracy: 0.9563 - val_loss: 0.1373 - val_accuracy: 0.9540\n",
      "Epoch 68/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1033 - accuracy: 0.9601 - val_loss: 0.1418 - val_accuracy: 0.9580\n",
      "Epoch 69/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0912 - accuracy: 0.9625 - val_loss: 0.1623 - val_accuracy: 0.9440\n",
      "Epoch 70/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1091 - accuracy: 0.9613 - val_loss: 0.1859 - val_accuracy: 0.9280\n",
      "Epoch 71/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0960 - accuracy: 0.9615 - val_loss: 0.1442 - val_accuracy: 0.9600\n",
      "Epoch 72/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9613 - val_loss: 0.1851 - val_accuracy: 0.9300\n",
      "Epoch 73/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1172 - accuracy: 0.9563 - val_loss: 0.1520 - val_accuracy: 0.9640\n",
      "Epoch 74/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9470 - val_loss: 0.2468 - val_accuracy: 0.9520\n",
      "Epoch 75/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1106 - accuracy: 0.9608 - val_loss: 0.1535 - val_accuracy: 0.9500\n",
      "Epoch 76/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1008 - accuracy: 0.9610 - val_loss: 0.1648 - val_accuracy: 0.9520\n",
      "Epoch 77/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1045 - accuracy: 0.9582 - val_loss: 0.1383 - val_accuracy: 0.9600\n",
      "Epoch 78/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0884 - accuracy: 0.9655 - val_loss: 0.2337 - val_accuracy: 0.9340\n",
      "Epoch 79/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0896 - accuracy: 0.9641 - val_loss: 0.1485 - val_accuracy: 0.9540\n",
      "Epoch 80/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0884 - accuracy: 0.9674 - val_loss: 0.1327 - val_accuracy: 0.9600\n",
      "Epoch 81/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0849 - accuracy: 0.9693 - val_loss: 0.1469 - val_accuracy: 0.9540\n",
      "Epoch 82/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1106 - accuracy: 0.9582 - val_loss: 0.1387 - val_accuracy: 0.9560\n",
      "Epoch 83/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0901 - accuracy: 0.9672 - val_loss: 0.1648 - val_accuracy: 0.9480\n",
      "Epoch 84/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9693 - val_loss: 0.1678 - val_accuracy: 0.9560\n",
      "Epoch 85/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0940 - accuracy: 0.9608 - val_loss: 0.1502 - val_accuracy: 0.9380\n",
      "Epoch 86/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0956 - accuracy: 0.9634 - val_loss: 0.2158 - val_accuracy: 0.9340\n",
      "Epoch 87/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0875 - accuracy: 0.9674 - val_loss: 0.1351 - val_accuracy: 0.9580\n",
      "Epoch 88/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0928 - accuracy: 0.9634 - val_loss: 0.1506 - val_accuracy: 0.9560\n",
      "Epoch 89/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0957 - accuracy: 0.9627 - val_loss: 0.1377 - val_accuracy: 0.9480\n",
      "Epoch 90/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0840 - accuracy: 0.9696 - val_loss: 0.1337 - val_accuracy: 0.9640\n",
      "Epoch 91/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0871 - accuracy: 0.9689 - val_loss: 0.1325 - val_accuracy: 0.9600\n",
      "Epoch 92/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0943 - accuracy: 0.9622 - val_loss: 0.1906 - val_accuracy: 0.9560\n",
      "Epoch 93/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0960 - accuracy: 0.9646 - val_loss: 0.1643 - val_accuracy: 0.9280\n",
      "Epoch 94/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0948 - accuracy: 0.9636 - val_loss: 0.1318 - val_accuracy: 0.9660\n",
      "Epoch 95/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0922 - accuracy: 0.9636 - val_loss: 0.1418 - val_accuracy: 0.9620\n",
      "Epoch 96/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0882 - accuracy: 0.9684 - val_loss: 0.1274 - val_accuracy: 0.9640\n",
      "Epoch 97/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0841 - accuracy: 0.9679 - val_loss: 0.1413 - val_accuracy: 0.9680\n",
      "Epoch 98/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0919 - accuracy: 0.9632 - val_loss: 0.2341 - val_accuracy: 0.9220\n",
      "Epoch 99/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0883 - accuracy: 0.9684 - val_loss: 0.2380 - val_accuracy: 0.9480\n",
      "Epoch 100/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9682 - val_loss: 0.1954 - val_accuracy: 0.9540\n",
      "Epoch 101/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 0.9689 - val_loss: 0.1596 - val_accuracy: 0.9520\n",
      "Epoch 102/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0909 - accuracy: 0.9634 - val_loss: 0.1604 - val_accuracy: 0.9600\n",
      "Epoch 103/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0910 - accuracy: 0.9667 - val_loss: 0.1318 - val_accuracy: 0.9620\n",
      "Epoch 104/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0874 - accuracy: 0.9677 - val_loss: 0.1485 - val_accuracy: 0.9640\n",
      "Epoch 105/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0905 - accuracy: 0.9629 - val_loss: 0.1309 - val_accuracy: 0.9640\n",
      "Epoch 106/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0764 - accuracy: 0.9698 - val_loss: 0.1262 - val_accuracy: 0.9660\n",
      "Epoch 107/500\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0751 - accuracy: 0.9739 - val_loss: 0.1481 - val_accuracy: 0.9660\n",
      "Epoch 108/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0945 - accuracy: 0.9653 - val_loss: 0.1681 - val_accuracy: 0.9420\n",
      "Epoch 109/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9693 - val_loss: 0.1342 - val_accuracy: 0.9580\n",
      "Epoch 110/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0756 - accuracy: 0.9689 - val_loss: 0.1542 - val_accuracy: 0.9680\n",
      "Epoch 111/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0831 - accuracy: 0.9686 - val_loss: 0.1879 - val_accuracy: 0.9360\n",
      "Epoch 112/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0933 - accuracy: 0.9653 - val_loss: 0.1559 - val_accuracy: 0.9480\n",
      "Epoch 113/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0845 - accuracy: 0.9684 - val_loss: 0.1545 - val_accuracy: 0.9680\n",
      "Epoch 114/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0745 - accuracy: 0.9720 - val_loss: 0.1276 - val_accuracy: 0.9700\n",
      "Epoch 115/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0962 - accuracy: 0.9644 - val_loss: 0.1878 - val_accuracy: 0.9540\n",
      "Epoch 116/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9691 - val_loss: 0.1630 - val_accuracy: 0.9380\n",
      "Epoch 117/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0865 - accuracy: 0.9663 - val_loss: 0.1564 - val_accuracy: 0.9420\n",
      "Epoch 118/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 0.9705 - val_loss: 0.1430 - val_accuracy: 0.9620\n",
      "Epoch 119/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0769 - accuracy: 0.9703 - val_loss: 0.1716 - val_accuracy: 0.9540\n",
      "Epoch 120/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 0.9708 - val_loss: 0.2538 - val_accuracy: 0.9520\n",
      "Epoch 121/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0871 - accuracy: 0.9625 - val_loss: 0.1266 - val_accuracy: 0.9600\n",
      "Epoch 122/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0843 - accuracy: 0.9679 - val_loss: 0.1538 - val_accuracy: 0.9500\n",
      "Epoch 123/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0862 - accuracy: 0.9644 - val_loss: 0.1334 - val_accuracy: 0.9660\n",
      "Epoch 124/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0908 - accuracy: 0.9646 - val_loss: 0.1256 - val_accuracy: 0.9640\n",
      "Epoch 125/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0787 - accuracy: 0.9708 - val_loss: 0.1896 - val_accuracy: 0.9360\n",
      "Epoch 126/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0795 - accuracy: 0.9715 - val_loss: 0.2370 - val_accuracy: 0.9360\n",
      "Epoch 127/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9729 - val_loss: 0.1673 - val_accuracy: 0.9660\n",
      "Epoch 128/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0823 - accuracy: 0.9701 - val_loss: 0.1472 - val_accuracy: 0.9620\n",
      "Epoch 129/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0753 - accuracy: 0.9684 - val_loss: 0.1465 - val_accuracy: 0.9600\n",
      "Epoch 130/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0785 - accuracy: 0.9682 - val_loss: 0.1546 - val_accuracy: 0.9500\n",
      "Epoch 131/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0842 - accuracy: 0.9679 - val_loss: 0.1372 - val_accuracy: 0.9600\n",
      "Epoch 132/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9772 - val_loss: 0.1390 - val_accuracy: 0.9600\n",
      "Epoch 133/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0819 - accuracy: 0.9691 - val_loss: 0.1616 - val_accuracy: 0.9620\n",
      "Epoch 134/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.9731 - val_loss: 0.1530 - val_accuracy: 0.9660\n",
      "Epoch 135/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9693 - val_loss: 0.2454 - val_accuracy: 0.9560\n",
      "Epoch 136/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0961 - accuracy: 0.9634 - val_loss: 0.1827 - val_accuracy: 0.9460\n",
      "Epoch 137/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0827 - accuracy: 0.9698 - val_loss: 0.1573 - val_accuracy: 0.9460\n",
      "Epoch 138/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0840 - accuracy: 0.9717 - val_loss: 0.1605 - val_accuracy: 0.9600\n",
      "Epoch 139/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0937 - accuracy: 0.9670 - val_loss: 0.1538 - val_accuracy: 0.9660\n",
      "Epoch 140/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9758 - val_loss: 0.1405 - val_accuracy: 0.9440\n",
      "Epoch 141/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.9734 - val_loss: 0.1495 - val_accuracy: 0.9520\n",
      "Epoch 142/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9760 - val_loss: 0.1498 - val_accuracy: 0.9600\n",
      "Epoch 143/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.9729 - val_loss: 0.1345 - val_accuracy: 0.9600\n",
      "Epoch 144/500\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.9722 - val_loss: 0.1855 - val_accuracy: 0.9520\n",
      "Epoch 145/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9753 - val_loss: 0.1680 - val_accuracy: 0.9620\n",
      "Epoch 146/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0739 - accuracy: 0.9739 - val_loss: 0.1306 - val_accuracy: 0.9640\n",
      "Epoch 147/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9739 - val_loss: 0.1532 - val_accuracy: 0.9420\n",
      "Epoch 148/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0768 - accuracy: 0.9712 - val_loss: 0.1957 - val_accuracy: 0.9640\n",
      "Epoch 149/500\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.9739 - val_loss: 0.1292 - val_accuracy: 0.9700\n",
      "\n",
      "\n",
      "\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.1156 - accuracy: 0.9637\n"
     ]
    }
   ],
   "source": [
    "def build_last_fnn_model():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "\n",
    "    model.add(keras.layers.Dense(512, activation='relu'))\n",
    "    model.add(keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(keras.layers.Dense(512, activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_last_fnn_model(model):\n",
    "    model.fit(x_train_images, x_train_labels, epochs=500,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_valid_images, x_valid_labels),\n",
    "                    callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=35)])\n",
    "\n",
    "last_fnn = build_last_fnn_model()\n",
    "train_last_fnn_model(last_fnn)\n",
    "print(\"\\n\\n\")\n",
    "cur_loss, cur_acc = last_fnn.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrambe le reti FNN ottengono lo stesso valore di accuracy 0.9637, ma i valori di loss sono leggermente differenti. Entrambe raggiungono delle prestazioni interessanti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8evNMcPP-2b1"
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gianl\\anaconda3\\envs\\ML-GPU\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\gianl\\anaconda3\\envs\\ML-GPU\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#a causa di problemi di versioni di python, non si è potuta utilizzare la loss function binary_focal_crossentropy (interessante da provare), in modo diretto.\n",
    "#per risolvere questi problemi si è usata una versione precedente della funzione di loss che è la sigmoid_focal_crossentropy, che però richiede il seguente import\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1708100752491,
     "user": {
      "displayName": "Gianluca Maccari",
      "userId": "05720923772203941125"
     },
     "user_tz": -60
    },
    "id": "JfEVwYpdxASe"
   },
   "outputs": [],
   "source": [
    "x_tensor_train = x_train_images.reshape(-1,28,28,1)\n",
    "x_tensor_valid = x_valid_images.reshape(-1,28,28,1)\n",
    "test_tensor = test_images.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si utilizza come prima rete cnn la rete LeNet, ma come funzioni di attivazioni sono state utilizzate le relu (al posto delle sigmoid). \n",
    "Questa rete viene utilizzata anche per testare la miglior loss function per il task in questione.\n",
    "Come per le reti precedenti, si aggiunge un livello finale per la binary classification.\n",
    "Inoltre si testa quale sia la miglior operazione del livello di pooling tra max pooling e average pooling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lenet(pool_type, loss):\n",
    "    \n",
    "    lenet = tf.keras.models.Sequential()\n",
    "    lenet.add(keras.layers.Conv2D(filters=6, kernel_size=5, activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
    "            \n",
    "    if(pool_type == 1):\n",
    "        lenet.add(keras.layers.AvgPool2D(pool_size=2, strides=2))\n",
    "    else:\n",
    "        lenet.add(keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "            \n",
    "    lenet.add(keras.layers.Conv2D(filters=16, kernel_size=5, activation='relu'))\n",
    "\n",
    "    if(pool_type == 1):\n",
    "        lenet.add(keras.layers.AvgPool2D(pool_size=2, strides=2))\n",
    "    else:\n",
    "        lenet.add(keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "            \n",
    "    lenet.add(keras.layers.Flatten())\n",
    "    lenet.add(keras.layers.Dense(120, activation='relu'))\n",
    "    lenet.add(keras.layers.Dense(84, activation='relu'))\n",
    "    lenet.add(keras.layers.Dense(10, activation='relu'))\n",
    "    lenet.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    lenet.compile(loss=loss,\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "    return lenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risultati average pooling\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9714\n",
      "\n",
      "risultati max pooling\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0778 - accuracy: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07777874171733856, 0.9790076613426208]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet1 = build_lenet(1,\"binary_crossentropy\")\n",
    "lenet2 = build_lenet(2,\"binary_crossentropy\")\n",
    "\n",
    "lenet1.fit(x_tensor_train, x_train_labels, epochs=150, verbose=0,\n",
    "                    validation_data=(x_tensor_valid, x_valid_labels),\n",
    "          callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=10)])\n",
    "lenet2.fit(x_tensor_train, x_train_labels, epochs=150, verbose=0,\n",
    "                    validation_data=(x_tensor_valid, x_valid_labels),\n",
    "          callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=10)])\n",
    "print(\"risultati average pooling\")\n",
    "lenet1.evaluate(test_tensor, test_labels)\n",
    "print(\"\\nrisultati max pooling\")\n",
    "lenet2.evaluate(test_tensor, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In generale le due operazioni di pooling non hanno prestazioni molto differenti per quanto riguarda l'accuracy sul test set. La loss sul test set in più iterazioni sembra risultare più bassa (di poco) con il max pooling.\n",
    "Si sceglie dunque il max pooling come livello di pooling dei successivi modelli.\n",
    "\n",
    "Per la scelta della loss function vengono testate 3 loss function:loss1 = \"binary_crossentropy\", \"mean_squared_error\" e \"binary_focal_crossentropy\" (quest'ultima per problemi di compatibilità, è stata sostituita con la versione precedente \"sigmoid_focal_crossentropy\"). Vengono testate usando LeNet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risultati per binary cross entropy\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9676\n",
      "\n",
      "risultati per MSE\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0286 - accuracy: 0.9618\n",
      "\n",
      "risultati per binary focal cross entropy\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0126 - accuracy: 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.012580136768519878, 0.9770992398262024]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss1 = \"binary_crossentropy\"\n",
    "loss2 = \"mean_squared_error\"\n",
    "loss3 = tfa.losses.sigmoid_focal_crossentropy\n",
    "\n",
    "lenet_loss1 = build_lenet(2,loss1)\n",
    "lenet_loss2 = build_lenet(2,loss2)\n",
    "lenet_loss3 = build_lenet(2,loss3)\n",
    "\n",
    "lenet_loss1.fit(x_tensor_train, x_train_labels, epochs=200, verbose=0,\n",
    "                    validation_data=(x_tensor_valid, x_valid_labels),\n",
    "          callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=20)])\n",
    "lenet_loss2.fit(x_tensor_train, x_train_labels, epochs=200, verbose=0,\n",
    "                    validation_data=(x_tensor_valid, x_valid_labels),\n",
    "          callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=20)])\n",
    "lenet_loss3.fit(x_tensor_train, x_train_labels, epochs=200, verbose=0,\n",
    "                    validation_data=(x_tensor_valid, x_valid_labels),\n",
    "          callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=20)])\n",
    "\n",
    "print(\"risultati per binary cross entropy\")\n",
    "lenet_loss1.evaluate(test_tensor, test_labels)\n",
    "print(\"\\nrisultati per MSE\")\n",
    "lenet_loss2.evaluate(test_tensor, test_labels)\n",
    "print(\"\\nrisultati per binary focal cross entropy\")\n",
    "lenet_loss3.evaluate(test_tensor, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nota come la binary focal cross entropy sia la migliore delle loss function, quindi si utilizza questa come loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si estende LeNet con altri 3 livelli convoluzionali e due livelli di max pooling. Inoltre tutti i livelli convoluzionali applicano padding in modo tale che dimensione di input = dimensione output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "132/132 [==============================] - 2s 6ms/step - loss: 0.0322 - accuracy: 0.8039 - val_loss: 0.0195 - val_accuracy: 0.9300\n",
      "Epoch 2/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 0.9356 - val_loss: 0.0199 - val_accuracy: 0.9460\n",
      "Epoch 3/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9458 - val_loss: 0.0152 - val_accuracy: 0.9300\n",
      "Epoch 4/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9432 - val_loss: 0.0161 - val_accuracy: 0.9500\n",
      "Epoch 5/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9444 - val_loss: 0.0136 - val_accuracy: 0.9420\n",
      "Epoch 6/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9565 - val_loss: 0.0176 - val_accuracy: 0.9120\n",
      "Epoch 7/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 0.9563 - val_loss: 0.0201 - val_accuracy: 0.9520\n",
      "Epoch 8/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9629 - val_loss: 0.0123 - val_accuracy: 0.9620\n",
      "Epoch 9/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9663 - val_loss: 0.0131 - val_accuracy: 0.9560\n",
      "Epoch 10/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9682 - val_loss: 0.0127 - val_accuracy: 0.9440\n",
      "Epoch 11/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9577 - val_loss: 0.0122 - val_accuracy: 0.9500\n",
      "Epoch 12/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9677 - val_loss: 0.0120 - val_accuracy: 0.9680\n",
      "Epoch 13/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9703 - val_loss: 0.0121 - val_accuracy: 0.9520\n",
      "Epoch 14/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9755 - val_loss: 0.0157 - val_accuracy: 0.9660\n",
      "Epoch 15/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9727 - val_loss: 0.0122 - val_accuracy: 0.9600\n",
      "Epoch 16/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9786 - val_loss: 0.0123 - val_accuracy: 0.9660\n",
      "Epoch 17/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9750 - val_loss: 0.0131 - val_accuracy: 0.9400\n",
      "Epoch 18/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9743 - val_loss: 0.0123 - val_accuracy: 0.9540\n",
      "Epoch 19/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9750 - val_loss: 0.0138 - val_accuracy: 0.9600\n",
      "Epoch 20/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9817 - val_loss: 0.0132 - val_accuracy: 0.9640\n",
      "Epoch 21/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9827 - val_loss: 0.0104 - val_accuracy: 0.9480\n",
      "Epoch 22/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9781 - val_loss: 0.0266 - val_accuracy: 0.9720\n",
      "Epoch 23/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9808 - val_loss: 0.0127 - val_accuracy: 0.9480\n",
      "Epoch 24/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9774 - val_loss: 0.0102 - val_accuracy: 0.9460\n",
      "Epoch 25/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9800 - val_loss: 0.0128 - val_accuracy: 0.9580\n",
      "Epoch 26/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9843 - val_loss: 0.0218 - val_accuracy: 0.9620\n",
      "Epoch 27/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9810 - val_loss: 0.0104 - val_accuracy: 0.9520\n",
      "Epoch 28/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 0.9824 - val_loss: 0.0093 - val_accuracy: 0.9560\n",
      "Epoch 29/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9831 - val_loss: 0.0227 - val_accuracy: 0.9700\n",
      "Epoch 30/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 0.9910 - val_loss: 0.0355 - val_accuracy: 0.9680\n",
      "Epoch 31/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9869 - val_loss: 0.0151 - val_accuracy: 0.9660\n",
      "Epoch 32/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9822 - val_loss: 0.0158 - val_accuracy: 0.9600\n",
      "Epoch 33/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9895 - val_loss: 0.0272 - val_accuracy: 0.9640\n",
      "Epoch 34/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9774 - val_loss: 0.0113 - val_accuracy: 0.9680\n",
      "Epoch 35/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 0.9798 - val_loss: 0.0177 - val_accuracy: 0.9640\n",
      "Epoch 36/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 0.9865 - val_loss: 0.0114 - val_accuracy: 0.9620\n",
      "Epoch 37/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9919 - val_loss: 0.0121 - val_accuracy: 0.9600\n",
      "Epoch 38/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9812 - val_loss: 0.0126 - val_accuracy: 0.9620\n",
      "Epoch 39/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9739 - val_loss: 0.0153 - val_accuracy: 0.9660\n",
      "Epoch 40/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9876 - val_loss: 0.0132 - val_accuracy: 0.9520\n",
      "Epoch 41/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9862 - val_loss: 0.0133 - val_accuracy: 0.9660\n",
      "Epoch 42/200\n",
      "132/132 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 0.9929 - val_loss: 0.0196 - val_accuracy: 0.9680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a81da8cf10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1 = tf.keras.models.Sequential([\n",
    "            #input 28x28\n",
    "            tf.keras.layers.Conv2D(filters=6, kernel_size=5, activation='relu', padding='same', input_shape=(28, 28, 1)),\n",
    "            #input 28x28\n",
    "            tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "            #input 14x14\n",
    "            tf.keras.layers.Conv2D(filters=16, kernel_size=5, activation='relu', padding='same'),\n",
    "            #input 14x14\n",
    "            tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "            #input 7x7\n",
    "            tf.keras.layers.Conv2D(filters=30, kernel_size=5, activation='relu', padding='same'),\n",
    "            #input 7x7\n",
    "            tf.keras.layers.MaxPool2D(pool_size=2, strides=1),\n",
    "            #input 6x6\n",
    "            tf.keras.layers.Conv2D(filters=50, kernel_size=5, activation='relu', padding='same'),\n",
    "            #input 6x6\n",
    "            tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "            #input 3x3\n",
    "            tf.keras.layers.Conv2D(filters=80, kernel_size=3, activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(120, activation='relu'),\n",
    "            tf.keras.layers.Dense(84, activation='relu'),\n",
    "            tf.keras.layers.Dense(10, activation='relu'),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "cnn1.compile(loss=loss3,\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "cnn1.fit(x_tensor_train, x_train_labels, epochs=200,\n",
    "                    validation_data=(x_tensor_valid, x_valid_labels),\n",
    "          callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0209 - accuracy: 0.9733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.020896177738904953, 0.9732824563980103]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1.evaluate(test_tensor, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'accuracy di cnn1 in fase di training è molto alta, in alcune epoche tocca anche il valore 0.99, mentre nel testing l'accuracy scende allo 0.97. Anche la loss aumenta tra training e testing, quindi si cerca di diminuire l'overfitting applicando livelli di dropout.\n",
    "Si aumentano il numero di epoche e la patience.\n",
    "Sono stati testati i seguenti valori di dropout:0.10, 0.15, 0.20, 0.25, 0.30. I migliori risultati sono stati ottenuti con dropout 0.25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn2_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    #input 28x28\n",
    "    model.add(tf.keras.layers.Conv2D(filters=6, kernel_size=5, activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
    "    #input 28x28\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    #input 14x14\n",
    "    model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=5, activation='relu', padding='same'))\n",
    "    #input 14x14\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    #input 7x7\n",
    "    model.add(tf.keras.layers.Conv2D(filters=30, kernel_size=5, activation='relu', padding='same'))\n",
    "    #input 7x7\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=1))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    #input 6x6\n",
    "    model.add(tf.keras.layers.Conv2D(filters=50, kernel_size=5, activation='relu', padding='same'))\n",
    "    #input 6x6\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    #input 3x3\n",
    "    model.add(tf.keras.layers.Conv2D(filters=80, kernel_size=3, activation='relu'))\n",
    "            \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(120, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(84, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss=loss3,\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0657 - accuracy: 0.3760 - val_loss: 0.0667 - val_accuracy: 0.5220\n",
      "Epoch 2/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0506 - accuracy: 0.7517 - val_loss: 0.0501 - val_accuracy: 0.9080\n",
      "Epoch 3/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0378 - accuracy: 0.8988 - val_loss: 0.0313 - val_accuracy: 0.9180\n",
      "Epoch 4/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0314 - accuracy: 0.9185 - val_loss: 0.0293 - val_accuracy: 0.9500\n",
      "Epoch 5/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0302 - accuracy: 0.9133 - val_loss: 0.0282 - val_accuracy: 0.9480\n",
      "Epoch 6/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0248 - accuracy: 0.9318 - val_loss: 0.0218 - val_accuracy: 0.9460\n",
      "Epoch 7/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0248 - accuracy: 0.9287 - val_loss: 0.0212 - val_accuracy: 0.9360\n",
      "Epoch 8/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0238 - accuracy: 0.9285 - val_loss: 0.0211 - val_accuracy: 0.9660\n",
      "Epoch 9/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0209 - accuracy: 0.9351 - val_loss: 0.0179 - val_accuracy: 0.9620\n",
      "Epoch 10/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0195 - accuracy: 0.9420 - val_loss: 0.0272 - val_accuracy: 0.9540\n",
      "Epoch 11/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0187 - accuracy: 0.9430 - val_loss: 0.0216 - val_accuracy: 0.9580\n",
      "Epoch 12/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0194 - accuracy: 0.9432 - val_loss: 0.0159 - val_accuracy: 0.9600\n",
      "Epoch 13/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0158 - accuracy: 0.9373 - val_loss: 0.0159 - val_accuracy: 0.9600\n",
      "Epoch 14/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0161 - accuracy: 0.9373 - val_loss: 0.0136 - val_accuracy: 0.9540\n",
      "Epoch 15/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0139 - accuracy: 0.9480 - val_loss: 0.0137 - val_accuracy: 0.9260\n",
      "Epoch 16/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0166 - accuracy: 0.9342 - val_loss: 0.0165 - val_accuracy: 0.9500\n",
      "Epoch 17/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0154 - accuracy: 0.9439 - val_loss: 0.0124 - val_accuracy: 0.9580\n",
      "Epoch 18/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0138 - accuracy: 0.9456 - val_loss: 0.0135 - val_accuracy: 0.9300\n",
      "Epoch 19/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0144 - accuracy: 0.9406 - val_loss: 0.0131 - val_accuracy: 0.9360\n",
      "Epoch 20/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0134 - accuracy: 0.9529 - val_loss: 0.0120 - val_accuracy: 0.9540\n",
      "Epoch 21/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0141 - accuracy: 0.9430 - val_loss: 0.0131 - val_accuracy: 0.9620\n",
      "Epoch 22/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0119 - accuracy: 0.9527 - val_loss: 0.0120 - val_accuracy: 0.9440\n",
      "Epoch 23/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0134 - accuracy: 0.9461 - val_loss: 0.0130 - val_accuracy: 0.9520\n",
      "Epoch 24/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0128 - accuracy: 0.9513 - val_loss: 0.0128 - val_accuracy: 0.9520\n",
      "Epoch 25/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0139 - accuracy: 0.9518 - val_loss: 0.0107 - val_accuracy: 0.9640\n",
      "Epoch 26/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0125 - accuracy: 0.9499 - val_loss: 0.0110 - val_accuracy: 0.9600\n",
      "Epoch 27/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0119 - accuracy: 0.9541 - val_loss: 0.0110 - val_accuracy: 0.9540\n",
      "Epoch 28/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0122 - accuracy: 0.9567 - val_loss: 0.0101 - val_accuracy: 0.9580\n",
      "Epoch 29/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0149 - accuracy: 0.9420 - val_loss: 0.0121 - val_accuracy: 0.9520\n",
      "Epoch 30/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0129 - accuracy: 0.9529 - val_loss: 0.0151 - val_accuracy: 0.9580\n",
      "Epoch 31/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0151 - accuracy: 0.9342 - val_loss: 0.0135 - val_accuracy: 0.9640\n",
      "Epoch 32/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0142 - accuracy: 0.9456 - val_loss: 0.0121 - val_accuracy: 0.9340\n",
      "Epoch 33/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0128 - accuracy: 0.9463 - val_loss: 0.0132 - val_accuracy: 0.9720\n",
      "Epoch 34/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0120 - accuracy: 0.9525 - val_loss: 0.0161 - val_accuracy: 0.9520\n",
      "Epoch 35/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0152 - accuracy: 0.9337 - val_loss: 0.0126 - val_accuracy: 0.9560\n",
      "Epoch 36/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0125 - accuracy: 0.9539 - val_loss: 0.0107 - val_accuracy: 0.9520\n",
      "Epoch 37/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0121 - accuracy: 0.9499 - val_loss: 0.0120 - val_accuracy: 0.9560\n",
      "Epoch 38/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0124 - accuracy: 0.9548 - val_loss: 0.0101 - val_accuracy: 0.9640\n",
      "Epoch 39/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0136 - accuracy: 0.9463 - val_loss: 0.0147 - val_accuracy: 0.9520\n",
      "Epoch 40/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0115 - accuracy: 0.9532 - val_loss: 0.0111 - val_accuracy: 0.9480\n",
      "Epoch 41/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0118 - accuracy: 0.9527 - val_loss: 0.0135 - val_accuracy: 0.9320\n",
      "Epoch 42/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0119 - accuracy: 0.9494 - val_loss: 0.0113 - val_accuracy: 0.9480\n",
      "Epoch 43/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9620 - val_loss: 0.0114 - val_accuracy: 0.9480\n",
      "Epoch 44/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0109 - accuracy: 0.9589 - val_loss: 0.0115 - val_accuracy: 0.9480\n",
      "Epoch 45/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0116 - accuracy: 0.9553 - val_loss: 0.0132 - val_accuracy: 0.9640\n",
      "Epoch 46/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0122 - accuracy: 0.9522 - val_loss: 0.0126 - val_accuracy: 0.9580\n",
      "Epoch 47/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0115 - accuracy: 0.9541 - val_loss: 0.0128 - val_accuracy: 0.9580\n",
      "Epoch 48/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0117 - accuracy: 0.9544 - val_loss: 0.0157 - val_accuracy: 0.9640\n",
      "Epoch 49/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9539 - val_loss: 0.0118 - val_accuracy: 0.9680\n",
      "Epoch 50/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9558 - val_loss: 0.0122 - val_accuracy: 0.9640\n",
      "Epoch 51/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0100 - accuracy: 0.9627 - val_loss: 0.0117 - val_accuracy: 0.9660\n",
      "Epoch 52/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.9591 - val_loss: 0.0132 - val_accuracy: 0.9700\n",
      "Epoch 53/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9610 - val_loss: 0.0124 - val_accuracy: 0.9540\n",
      "Epoch 54/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.9632 - val_loss: 0.0122 - val_accuracy: 0.9560\n",
      "Epoch 55/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9653 - val_loss: 0.0106 - val_accuracy: 0.9580\n",
      "Epoch 56/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9622 - val_loss: 0.0102 - val_accuracy: 0.9640\n",
      "Epoch 57/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9625 - val_loss: 0.0098 - val_accuracy: 0.9600\n",
      "Epoch 58/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.9584 - val_loss: 0.0099 - val_accuracy: 0.9600\n",
      "Epoch 59/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9610 - val_loss: 0.0117 - val_accuracy: 0.9500\n",
      "Epoch 60/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9477 - val_loss: 0.0123 - val_accuracy: 0.9460\n",
      "Epoch 61/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.9589 - val_loss: 0.0103 - val_accuracy: 0.9660\n",
      "Epoch 62/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.9563 - val_loss: 0.0115 - val_accuracy: 0.9460\n",
      "Epoch 63/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0096 - accuracy: 0.9565 - val_loss: 0.0121 - val_accuracy: 0.9620\n",
      "Epoch 64/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0116 - accuracy: 0.9560 - val_loss: 0.0155 - val_accuracy: 0.9280\n",
      "Epoch 65/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.9615 - val_loss: 0.0108 - val_accuracy: 0.9480\n",
      "Epoch 66/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9567 - val_loss: 0.0103 - val_accuracy: 0.9520\n",
      "Epoch 67/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.9627 - val_loss: 0.0105 - val_accuracy: 0.9580\n",
      "Epoch 68/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.9620 - val_loss: 0.0110 - val_accuracy: 0.9540\n",
      "Epoch 69/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9617 - val_loss: 0.0104 - val_accuracy: 0.9640\n",
      "Epoch 70/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0125 - accuracy: 0.9518 - val_loss: 0.0109 - val_accuracy: 0.9480\n",
      "Epoch 71/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0116 - accuracy: 0.9587 - val_loss: 0.0109 - val_accuracy: 0.9520\n",
      "Epoch 72/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.9667 - val_loss: 0.0100 - val_accuracy: 0.9560\n",
      "Epoch 73/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0096 - accuracy: 0.9622 - val_loss: 0.0128 - val_accuracy: 0.9360\n",
      "Epoch 74/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0086 - accuracy: 0.9660 - val_loss: 0.0100 - val_accuracy: 0.9660\n",
      "Epoch 75/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9634 - val_loss: 0.0107 - val_accuracy: 0.9620\n",
      "Epoch 76/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9615 - val_loss: 0.0095 - val_accuracy: 0.9520\n",
      "Epoch 77/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9658 - val_loss: 0.0105 - val_accuracy: 0.9540\n",
      "Epoch 78/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.9639 - val_loss: 0.0115 - val_accuracy: 0.9560\n",
      "Epoch 79/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.9641 - val_loss: 0.0220 - val_accuracy: 0.9040\n",
      "Epoch 80/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0119 - accuracy: 0.9522 - val_loss: 0.0139 - val_accuracy: 0.9280\n",
      "Epoch 81/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.9634 - val_loss: 0.0114 - val_accuracy: 0.9540\n",
      "Epoch 82/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0110 - accuracy: 0.9591 - val_loss: 0.0123 - val_accuracy: 0.9640\n",
      "Epoch 83/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0100 - accuracy: 0.9589 - val_loss: 0.0107 - val_accuracy: 0.9560\n",
      "Epoch 84/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.9584 - val_loss: 0.0099 - val_accuracy: 0.9640\n",
      "Epoch 85/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9617 - val_loss: 0.0100 - val_accuracy: 0.9600\n",
      "Epoch 86/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.9648 - val_loss: 0.0120 - val_accuracy: 0.9480\n",
      "Epoch 87/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9672 - val_loss: 0.0112 - val_accuracy: 0.9480\n",
      "Epoch 88/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0147 - accuracy: 0.9470 - val_loss: 0.0120 - val_accuracy: 0.9460\n",
      "Epoch 89/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.9636 - val_loss: 0.0112 - val_accuracy: 0.9480\n",
      "Epoch 90/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.9598 - val_loss: 0.0115 - val_accuracy: 0.9580\n",
      "Epoch 91/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0194 - accuracy: 0.9249 - val_loss: 0.0138 - val_accuracy: 0.9560\n",
      "Epoch 92/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0158 - accuracy: 0.9392 - val_loss: 0.0138 - val_accuracy: 0.9340\n",
      "Epoch 93/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0172 - accuracy: 0.9382 - val_loss: 0.0131 - val_accuracy: 0.9480\n",
      "Epoch 94/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 0.9385 - val_loss: 0.0127 - val_accuracy: 0.9440\n",
      "Epoch 95/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0121 - accuracy: 0.9527 - val_loss: 0.0150 - val_accuracy: 0.9300\n",
      "Epoch 96/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9499 - val_loss: 0.0126 - val_accuracy: 0.9560\n",
      "Epoch 97/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9603 - val_loss: 0.0118 - val_accuracy: 0.9400\n",
      "Epoch 98/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.9575 - val_loss: 0.0099 - val_accuracy: 0.9620\n",
      "Epoch 99/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.9610 - val_loss: 0.0102 - val_accuracy: 0.9580\n",
      "Epoch 100/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0115 - accuracy: 0.9608 - val_loss: 0.0100 - val_accuracy: 0.9620\n",
      "Epoch 101/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0096 - accuracy: 0.9617 - val_loss: 0.0095 - val_accuracy: 0.9700\n",
      "Epoch 102/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.9679 - val_loss: 0.0097 - val_accuracy: 0.9480\n",
      "Epoch 103/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9670 - val_loss: 0.0097 - val_accuracy: 0.9680\n",
      "Epoch 104/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9679 - val_loss: 0.0106 - val_accuracy: 0.9680\n",
      "Epoch 105/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 0.9696 - val_loss: 0.0099 - val_accuracy: 0.9620\n",
      "Epoch 106/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0133 - accuracy: 0.9620 - val_loss: 0.0122 - val_accuracy: 0.9620\n",
      "Epoch 107/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0117 - accuracy: 0.9520 - val_loss: 0.0109 - val_accuracy: 0.9540\n",
      "Epoch 108/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0106 - accuracy: 0.9560 - val_loss: 0.0123 - val_accuracy: 0.9500\n",
      "Epoch 109/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0122 - accuracy: 0.9598 - val_loss: 0.0115 - val_accuracy: 0.9640\n",
      "Epoch 110/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.9667 - val_loss: 0.0112 - val_accuracy: 0.9680\n",
      "Epoch 111/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.9686 - val_loss: 0.0102 - val_accuracy: 0.9580\n",
      "Epoch 112/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.9627 - val_loss: 0.0104 - val_accuracy: 0.9680\n",
      "Epoch 113/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.9660 - val_loss: 0.0107 - val_accuracy: 0.9660\n",
      "Epoch 114/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.9691 - val_loss: 0.0101 - val_accuracy: 0.9680\n",
      "Epoch 115/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 0.9667 - val_loss: 0.0097 - val_accuracy: 0.9700\n",
      "Epoch 116/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9644 - val_loss: 0.0110 - val_accuracy: 0.9700\n",
      "Epoch 117/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.9703 - val_loss: 0.0091 - val_accuracy: 0.9600\n",
      "Epoch 118/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.9689 - val_loss: 0.0122 - val_accuracy: 0.9520\n",
      "Epoch 119/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0114 - accuracy: 0.9589 - val_loss: 0.0120 - val_accuracy: 0.9560\n",
      "Epoch 120/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.9634 - val_loss: 0.0105 - val_accuracy: 0.9680\n",
      "Epoch 121/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 0.9693 - val_loss: 0.0109 - val_accuracy: 0.9560\n",
      "Epoch 122/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9717 - val_loss: 0.0116 - val_accuracy: 0.9480\n",
      "Epoch 123/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0235 - accuracy: 0.9323 - val_loss: 0.0137 - val_accuracy: 0.9540\n",
      "Epoch 124/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0132 - accuracy: 0.9515 - val_loss: 0.0138 - val_accuracy: 0.9340\n",
      "Epoch 125/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.9582 - val_loss: 0.0107 - val_accuracy: 0.9660\n",
      "Epoch 126/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9665 - val_loss: 0.0118 - val_accuracy: 0.9460\n",
      "Epoch 127/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9703 - val_loss: 0.0149 - val_accuracy: 0.9360\n",
      "Epoch 128/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9670 - val_loss: 0.0115 - val_accuracy: 0.9680\n",
      "Epoch 129/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0149 - accuracy: 0.9480 - val_loss: 0.0146 - val_accuracy: 0.9300\n",
      "Epoch 130/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9556 - val_loss: 0.0123 - val_accuracy: 0.9540\n",
      "Epoch 131/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.9646 - val_loss: 0.0122 - val_accuracy: 0.9380\n",
      "Epoch 132/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0086 - accuracy: 0.9625 - val_loss: 0.0132 - val_accuracy: 0.9600\n",
      "Epoch 133/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.9620 - val_loss: 0.0125 - val_accuracy: 0.9560\n",
      "Epoch 134/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0085 - accuracy: 0.9691 - val_loss: 0.0145 - val_accuracy: 0.9380\n",
      "Epoch 135/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.9646 - val_loss: 0.0109 - val_accuracy: 0.9540\n",
      "Epoch 136/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0136 - accuracy: 0.9520 - val_loss: 0.0143 - val_accuracy: 0.9420\n",
      "Epoch 137/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0126 - accuracy: 0.9510 - val_loss: 0.0113 - val_accuracy: 0.9600\n",
      "Epoch 138/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0094 - accuracy: 0.9679 - val_loss: 0.0109 - val_accuracy: 0.9680\n",
      "Epoch 139/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9627 - val_loss: 0.0133 - val_accuracy: 0.9520\n",
      "Epoch 140/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0138 - accuracy: 0.9570 - val_loss: 0.0127 - val_accuracy: 0.9440\n",
      "Epoch 141/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0162 - accuracy: 0.9449 - val_loss: 0.0132 - val_accuracy: 0.9360\n",
      "Epoch 142/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9584 - val_loss: 0.0112 - val_accuracy: 0.9620\n",
      "Epoch 143/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.9651 - val_loss: 0.0092 - val_accuracy: 0.9660\n",
      "Epoch 144/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.9693 - val_loss: 0.0107 - val_accuracy: 0.9680\n",
      "Epoch 145/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9655 - val_loss: 0.0109 - val_accuracy: 0.9580\n",
      "Epoch 146/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9670 - val_loss: 0.0112 - val_accuracy: 0.9560\n",
      "Epoch 147/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0197 - accuracy: 0.9499 - val_loss: 0.0271 - val_accuracy: 0.9360\n",
      "Epoch 148/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0310 - accuracy: 0.8653 - val_loss: 0.0172 - val_accuracy: 0.9500\n",
      "Epoch 149/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0193 - accuracy: 0.9190 - val_loss: 0.0253 - val_accuracy: 0.9300\n",
      "Epoch 150/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0230 - accuracy: 0.9221 - val_loss: 0.0154 - val_accuracy: 0.9520\n",
      "Epoch 151/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0159 - accuracy: 0.9385 - val_loss: 0.0120 - val_accuracy: 0.9480\n",
      "Epoch 152/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0178 - accuracy: 0.9330 - val_loss: 0.0198 - val_accuracy: 0.9580\n",
      "Epoch 153/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0180 - accuracy: 0.9254 - val_loss: 0.0140 - val_accuracy: 0.9340\n",
      "Epoch 154/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0139 - accuracy: 0.9465 - val_loss: 0.0117 - val_accuracy: 0.9460\n",
      "Epoch 155/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0111 - accuracy: 0.9582 - val_loss: 0.0135 - val_accuracy: 0.9640\n",
      "Epoch 156/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9615 - val_loss: 0.0105 - val_accuracy: 0.9560\n",
      "Epoch 157/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9584 - val_loss: 0.0104 - val_accuracy: 0.9620\n",
      "Epoch 158/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9648 - val_loss: 0.0111 - val_accuracy: 0.9460\n",
      "Epoch 159/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9677 - val_loss: 0.0098 - val_accuracy: 0.9660\n",
      "Epoch 160/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.9705 - val_loss: 0.0103 - val_accuracy: 0.9680\n",
      "Epoch 161/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9689 - val_loss: 0.0121 - val_accuracy: 0.9460\n",
      "Epoch 162/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.9667 - val_loss: 0.0101 - val_accuracy: 0.9600\n",
      "Epoch 163/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 0.9660 - val_loss: 0.0109 - val_accuracy: 0.9660\n",
      "Epoch 164/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0165 - accuracy: 0.9432 - val_loss: 0.0157 - val_accuracy: 0.9560\n",
      "Epoch 165/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0128 - accuracy: 0.9472 - val_loss: 0.0107 - val_accuracy: 0.9520\n",
      "Epoch 166/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.9553 - val_loss: 0.0111 - val_accuracy: 0.9560\n",
      "Epoch 167/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9589 - val_loss: 0.0110 - val_accuracy: 0.9560\n",
      "Epoch 168/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.9648 - val_loss: 0.0107 - val_accuracy: 0.9660\n",
      "Epoch 169/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.9693 - val_loss: 0.0107 - val_accuracy: 0.9680\n",
      "Epoch 170/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.9682 - val_loss: 0.0097 - val_accuracy: 0.9620\n",
      "Epoch 171/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0080 - accuracy: 0.9696 - val_loss: 0.0117 - val_accuracy: 0.9580\n",
      "Epoch 172/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0080 - accuracy: 0.9660 - val_loss: 0.0096 - val_accuracy: 0.9600\n",
      "Epoch 173/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0073 - accuracy: 0.9722 - val_loss: 0.0097 - val_accuracy: 0.9680\n",
      "Epoch 174/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.9689 - val_loss: 0.0103 - val_accuracy: 0.9660\n",
      "Epoch 175/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0069 - accuracy: 0.9717 - val_loss: 0.0099 - val_accuracy: 0.9640\n",
      "Epoch 176/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0180 - accuracy: 0.9268 - val_loss: 0.0128 - val_accuracy: 0.9560\n",
      "Epoch 177/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9537 - val_loss: 0.0105 - val_accuracy: 0.9640\n",
      "Epoch 178/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9551 - val_loss: 0.0096 - val_accuracy: 0.9680\n",
      "Epoch 179/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0100 - accuracy: 0.9587 - val_loss: 0.0100 - val_accuracy: 0.9640\n",
      "Epoch 180/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0166 - accuracy: 0.9358 - val_loss: 0.0172 - val_accuracy: 0.9400\n",
      "Epoch 181/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0136 - accuracy: 0.9491 - val_loss: 0.0126 - val_accuracy: 0.9500\n",
      "Epoch 182/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0125 - accuracy: 0.9491 - val_loss: 0.0113 - val_accuracy: 0.9580\n",
      "Epoch 183/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0122 - accuracy: 0.9518 - val_loss: 0.0114 - val_accuracy: 0.9540\n",
      "Epoch 184/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9620 - val_loss: 0.0130 - val_accuracy: 0.9320\n",
      "Epoch 185/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9601 - val_loss: 0.0124 - val_accuracy: 0.9640\n",
      "Epoch 186/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9629 - val_loss: 0.0098 - val_accuracy: 0.9580\n",
      "Epoch 187/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9665 - val_loss: 0.0091 - val_accuracy: 0.9640\n",
      "Epoch 188/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0138 - accuracy: 0.9503 - val_loss: 0.0166 - val_accuracy: 0.9500\n",
      "Epoch 189/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0145 - accuracy: 0.9458 - val_loss: 0.0144 - val_accuracy: 0.9620\n",
      "Epoch 190/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9603 - val_loss: 0.0128 - val_accuracy: 0.9620\n",
      "Epoch 191/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.9660 - val_loss: 0.0118 - val_accuracy: 0.9520\n",
      "Epoch 192/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9667 - val_loss: 0.0105 - val_accuracy: 0.9580\n",
      "Epoch 193/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.9698 - val_loss: 0.0110 - val_accuracy: 0.9600\n",
      "Epoch 194/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9682 - val_loss: 0.0105 - val_accuracy: 0.9600\n",
      "Epoch 195/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.9691 - val_loss: 0.0107 - val_accuracy: 0.9660\n",
      "Epoch 196/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0067 - accuracy: 0.9729 - val_loss: 0.0111 - val_accuracy: 0.9680\n",
      "Epoch 197/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.9646 - val_loss: 0.0113 - val_accuracy: 0.9640\n",
      "Epoch 198/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0163 - accuracy: 0.9316 - val_loss: 0.0144 - val_accuracy: 0.9460\n",
      "Epoch 199/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0127 - accuracy: 0.9525 - val_loss: 0.0110 - val_accuracy: 0.9600\n",
      "Epoch 200/200\n",
      "132/132 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.9665 - val_loss: 0.0112 - val_accuracy: 0.9620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a80d703f10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn2 = create_cnn2_model()\n",
    "\n",
    "cnn2.fit(x_tensor_train, x_train_labels, epochs=200,\n",
    "                    validation_data=(x_tensor_valid, x_valid_labels))\n",
    "          #callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=35)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.006713542155921459, 0.9790076613426208]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn2.evaluate(test_tensor, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultima modifica che si effettua a cnn2 è aumentare il numero di livelli dense e il numero di unità di tali livelli.\n",
    "Si utilizzano anche livelli di dropout per diminuire l'overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn3_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    #input 28x28\n",
    "    model.add(tf.keras.layers.Conv2D(filters=6, kernel_size=5, activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
    "    #input 28x28\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    #input 14x14\n",
    "    model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=5, activation='relu', padding='same'))\n",
    "    #input 14x14\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    #input 7x7\n",
    "    model.add(tf.keras.layers.Conv2D(filters=30, kernel_size=5, activation='relu', padding='same'))\n",
    "    #input 7x7\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=1))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    #input 6x6\n",
    "    model.add(tf.keras.layers.Conv2D(filters=50, kernel_size=5, activation='relu', padding='same'))\n",
    "    #input 6x6\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    #input 3x3\n",
    "    model.add(tf.keras.layers.Conv2D(filters=80, kernel_size=3, activation='relu'))\n",
    "            \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss=loss2,\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "132/132 [==============================] - 2s 7ms/step - loss: 0.1880 - accuracy: 0.7384 - val_loss: 0.2263 - val_accuracy: 0.7240\n",
      "Epoch 2/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.1270 - accuracy: 0.8099 - val_loss: 0.0929 - val_accuracy: 0.8860\n",
      "Epoch 3/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0970 - accuracy: 0.8769 - val_loss: 0.0949 - val_accuracy: 0.8820\n",
      "Epoch 4/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0823 - accuracy: 0.8945 - val_loss: 0.0778 - val_accuracy: 0.8960\n",
      "Epoch 5/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0728 - accuracy: 0.9059 - val_loss: 0.0561 - val_accuracy: 0.9260\n",
      "Epoch 6/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0690 - accuracy: 0.9114 - val_loss: 0.1067 - val_accuracy: 0.8720\n",
      "Epoch 7/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0627 - accuracy: 0.9223 - val_loss: 0.0498 - val_accuracy: 0.9320\n",
      "Epoch 8/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0575 - accuracy: 0.9211 - val_loss: 0.0766 - val_accuracy: 0.9040\n",
      "Epoch 9/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0482 - accuracy: 0.9401 - val_loss: 0.0397 - val_accuracy: 0.9460\n",
      "Epoch 10/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0527 - accuracy: 0.9339 - val_loss: 0.0526 - val_accuracy: 0.9300\n",
      "Epoch 11/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0488 - accuracy: 0.9370 - val_loss: 0.0447 - val_accuracy: 0.9460\n",
      "Epoch 12/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0484 - accuracy: 0.9375 - val_loss: 0.0383 - val_accuracy: 0.9360\n",
      "Epoch 13/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0468 - accuracy: 0.9406 - val_loss: 0.0722 - val_accuracy: 0.8980\n",
      "Epoch 14/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0426 - accuracy: 0.9442 - val_loss: 0.0376 - val_accuracy: 0.9520\n",
      "Epoch 15/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0445 - accuracy: 0.9430 - val_loss: 0.0615 - val_accuracy: 0.9140\n",
      "Epoch 16/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0385 - accuracy: 0.9501 - val_loss: 0.0457 - val_accuracy: 0.9360\n",
      "Epoch 17/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0430 - accuracy: 0.9475 - val_loss: 0.0371 - val_accuracy: 0.9520\n",
      "Epoch 18/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0392 - accuracy: 0.9501 - val_loss: 0.0365 - val_accuracy: 0.9520\n",
      "Epoch 19/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0432 - accuracy: 0.9437 - val_loss: 0.0348 - val_accuracy: 0.9460\n",
      "Epoch 20/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0373 - accuracy: 0.9510 - val_loss: 0.0400 - val_accuracy: 0.9380\n",
      "Epoch 21/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0405 - accuracy: 0.9491 - val_loss: 0.0452 - val_accuracy: 0.9360\n",
      "Epoch 22/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0373 - accuracy: 0.9539 - val_loss: 0.0612 - val_accuracy: 0.9200\n",
      "Epoch 23/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0400 - accuracy: 0.9456 - val_loss: 0.0345 - val_accuracy: 0.9520\n",
      "Epoch 24/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0352 - accuracy: 0.9532 - val_loss: 0.0329 - val_accuracy: 0.9560\n",
      "Epoch 25/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0369 - accuracy: 0.9532 - val_loss: 0.0369 - val_accuracy: 0.9580\n",
      "Epoch 26/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0383 - accuracy: 0.9529 - val_loss: 0.0328 - val_accuracy: 0.9540\n",
      "Epoch 27/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0356 - accuracy: 0.9541 - val_loss: 0.0358 - val_accuracy: 0.9500\n",
      "Epoch 28/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0351 - accuracy: 0.9577 - val_loss: 0.0381 - val_accuracy: 0.9440\n",
      "Epoch 29/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0334 - accuracy: 0.9567 - val_loss: 0.0374 - val_accuracy: 0.9440\n",
      "Epoch 30/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0322 - accuracy: 0.9556 - val_loss: 0.0322 - val_accuracy: 0.9580\n",
      "Epoch 31/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0326 - accuracy: 0.9601 - val_loss: 0.0405 - val_accuracy: 0.9500\n",
      "Epoch 32/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0348 - accuracy: 0.9544 - val_loss: 0.0286 - val_accuracy: 0.9600\n",
      "Epoch 33/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0317 - accuracy: 0.9589 - val_loss: 0.0313 - val_accuracy: 0.9580\n",
      "Epoch 34/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0342 - accuracy: 0.9539 - val_loss: 0.0405 - val_accuracy: 0.9520\n",
      "Epoch 35/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0303 - accuracy: 0.9629 - val_loss: 0.0275 - val_accuracy: 0.9620\n",
      "Epoch 36/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0421 - accuracy: 0.9503 - val_loss: 0.0346 - val_accuracy: 0.9520\n",
      "Epoch 37/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0314 - accuracy: 0.9608 - val_loss: 0.0283 - val_accuracy: 0.9620\n",
      "Epoch 38/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0363 - accuracy: 0.9518 - val_loss: 0.0393 - val_accuracy: 0.9440\n",
      "Epoch 39/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0308 - accuracy: 0.9620 - val_loss: 0.0547 - val_accuracy: 0.9360\n",
      "Epoch 40/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0372 - accuracy: 0.9522 - val_loss: 0.0321 - val_accuracy: 0.9580\n",
      "Epoch 41/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0321 - accuracy: 0.9594 - val_loss: 0.0300 - val_accuracy: 0.9600\n",
      "Epoch 42/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0309 - accuracy: 0.9627 - val_loss: 0.0303 - val_accuracy: 0.9600\n",
      "Epoch 43/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0330 - accuracy: 0.9541 - val_loss: 0.0336 - val_accuracy: 0.9500\n",
      "Epoch 44/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0344 - accuracy: 0.9518 - val_loss: 0.0319 - val_accuracy: 0.9680\n",
      "Epoch 45/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0286 - accuracy: 0.9608 - val_loss: 0.0399 - val_accuracy: 0.9580\n",
      "Epoch 46/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0272 - accuracy: 0.9651 - val_loss: 0.0312 - val_accuracy: 0.9600\n",
      "Epoch 47/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0347 - accuracy: 0.9544 - val_loss: 0.0295 - val_accuracy: 0.9660\n",
      "Epoch 48/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0276 - accuracy: 0.9663 - val_loss: 0.0339 - val_accuracy: 0.9600\n",
      "Epoch 49/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0314 - accuracy: 0.9603 - val_loss: 0.0345 - val_accuracy: 0.9540\n",
      "Epoch 50/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0300 - accuracy: 0.9596 - val_loss: 0.0305 - val_accuracy: 0.9600\n",
      "Epoch 51/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0274 - accuracy: 0.9655 - val_loss: 0.0315 - val_accuracy: 0.9660\n",
      "Epoch 52/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0293 - accuracy: 0.9610 - val_loss: 0.0343 - val_accuracy: 0.9600\n",
      "Epoch 53/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0348 - accuracy: 0.9544 - val_loss: 0.0269 - val_accuracy: 0.9640\n",
      "Epoch 54/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0294 - accuracy: 0.9613 - val_loss: 0.0472 - val_accuracy: 0.9420\n",
      "Epoch 55/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0325 - accuracy: 0.9560 - val_loss: 0.0319 - val_accuracy: 0.9660\n",
      "Epoch 56/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0388 - accuracy: 0.9496 - val_loss: 0.0294 - val_accuracy: 0.9620\n",
      "Epoch 57/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0323 - accuracy: 0.9603 - val_loss: 0.0261 - val_accuracy: 0.9700\n",
      "Epoch 58/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0297 - accuracy: 0.9641 - val_loss: 0.0335 - val_accuracy: 0.9540\n",
      "Epoch 59/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0308 - accuracy: 0.9608 - val_loss: 0.0281 - val_accuracy: 0.9660\n",
      "Epoch 60/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0272 - accuracy: 0.9677 - val_loss: 0.0294 - val_accuracy: 0.9640\n",
      "Epoch 61/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0281 - accuracy: 0.9632 - val_loss: 0.0424 - val_accuracy: 0.9400\n",
      "Epoch 62/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0335 - accuracy: 0.9558 - val_loss: 0.0297 - val_accuracy: 0.9520\n",
      "Epoch 63/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0293 - accuracy: 0.9608 - val_loss: 0.0369 - val_accuracy: 0.9520\n",
      "Epoch 64/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0332 - accuracy: 0.9582 - val_loss: 0.0308 - val_accuracy: 0.9660\n",
      "Epoch 65/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0315 - accuracy: 0.9596 - val_loss: 0.0288 - val_accuracy: 0.9600\n",
      "Epoch 66/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0293 - accuracy: 0.9639 - val_loss: 0.0350 - val_accuracy: 0.9560\n",
      "Epoch 67/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0295 - accuracy: 0.9625 - val_loss: 0.0274 - val_accuracy: 0.9620\n",
      "Epoch 68/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0270 - accuracy: 0.9670 - val_loss: 0.0278 - val_accuracy: 0.9660\n",
      "Epoch 69/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0281 - accuracy: 0.9641 - val_loss: 0.0363 - val_accuracy: 0.9520\n",
      "Epoch 70/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0325 - accuracy: 0.9601 - val_loss: 0.0332 - val_accuracy: 0.9580\n",
      "Epoch 71/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0326 - accuracy: 0.9584 - val_loss: 0.0294 - val_accuracy: 0.9660\n",
      "Epoch 72/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0299 - accuracy: 0.9617 - val_loss: 0.0284 - val_accuracy: 0.9660\n",
      "Epoch 73/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0263 - accuracy: 0.9674 - val_loss: 0.0298 - val_accuracy: 0.9580\n",
      "Epoch 74/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0271 - accuracy: 0.9629 - val_loss: 0.0281 - val_accuracy: 0.9660\n",
      "Epoch 75/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0533 - accuracy: 0.9330 - val_loss: 0.0400 - val_accuracy: 0.9420\n",
      "Epoch 76/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0342 - accuracy: 0.9560 - val_loss: 0.0372 - val_accuracy: 0.9460\n",
      "Epoch 77/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0254 - accuracy: 0.9677 - val_loss: 0.0288 - val_accuracy: 0.9660\n",
      "Epoch 78/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0256 - accuracy: 0.9670 - val_loss: 0.0261 - val_accuracy: 0.9640\n",
      "Epoch 79/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0244 - accuracy: 0.9693 - val_loss: 0.0250 - val_accuracy: 0.9640\n",
      "Epoch 80/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0282 - accuracy: 0.9639 - val_loss: 0.0249 - val_accuracy: 0.9600\n",
      "Epoch 81/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0280 - accuracy: 0.9622 - val_loss: 0.0244 - val_accuracy: 0.9720\n",
      "Epoch 82/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0237 - accuracy: 0.9674 - val_loss: 0.0262 - val_accuracy: 0.9700\n",
      "Epoch 83/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0298 - accuracy: 0.9620 - val_loss: 0.0322 - val_accuracy: 0.9640\n",
      "Epoch 84/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0259 - accuracy: 0.9655 - val_loss: 0.0244 - val_accuracy: 0.9720\n",
      "Epoch 85/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0239 - accuracy: 0.9710 - val_loss: 0.0250 - val_accuracy: 0.9720\n",
      "Epoch 86/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0294 - accuracy: 0.9617 - val_loss: 0.0252 - val_accuracy: 0.9740\n",
      "Epoch 87/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0243 - accuracy: 0.9708 - val_loss: 0.0306 - val_accuracy: 0.9600\n",
      "Epoch 88/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0236 - accuracy: 0.9696 - val_loss: 0.0245 - val_accuracy: 0.9700\n",
      "Epoch 89/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0281 - accuracy: 0.9655 - val_loss: 0.0241 - val_accuracy: 0.9760\n",
      "Epoch 90/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0255 - accuracy: 0.9686 - val_loss: 0.0279 - val_accuracy: 0.9640\n",
      "Epoch 91/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0239 - accuracy: 0.9703 - val_loss: 0.0235 - val_accuracy: 0.9740\n",
      "Epoch 92/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0291 - accuracy: 0.9634 - val_loss: 0.0306 - val_accuracy: 0.9640\n",
      "Epoch 93/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0325 - accuracy: 0.9610 - val_loss: 0.0284 - val_accuracy: 0.9660\n",
      "Epoch 94/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0322 - accuracy: 0.9606 - val_loss: 0.0257 - val_accuracy: 0.9680\n",
      "Epoch 95/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0266 - accuracy: 0.9663 - val_loss: 0.0252 - val_accuracy: 0.9720\n",
      "Epoch 96/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0289 - accuracy: 0.9634 - val_loss: 0.0244 - val_accuracy: 0.9740\n",
      "Epoch 97/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0272 - accuracy: 0.9670 - val_loss: 0.0267 - val_accuracy: 0.9660\n",
      "Epoch 98/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0251 - accuracy: 0.9665 - val_loss: 0.0251 - val_accuracy: 0.9680\n",
      "Epoch 99/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0213 - accuracy: 0.9724 - val_loss: 0.0256 - val_accuracy: 0.9720\n",
      "Epoch 100/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0231 - accuracy: 0.9708 - val_loss: 0.0283 - val_accuracy: 0.9600\n",
      "Epoch 101/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0249 - accuracy: 0.9667 - val_loss: 0.0275 - val_accuracy: 0.9640\n",
      "Epoch 102/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0224 - accuracy: 0.9734 - val_loss: 0.0333 - val_accuracy: 0.9580\n",
      "Epoch 103/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0244 - accuracy: 0.9684 - val_loss: 0.0308 - val_accuracy: 0.9560\n",
      "Epoch 104/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0267 - accuracy: 0.9667 - val_loss: 0.0255 - val_accuracy: 0.9720\n",
      "Epoch 105/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0264 - accuracy: 0.9679 - val_loss: 0.0316 - val_accuracy: 0.9660\n",
      "Epoch 106/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0231 - accuracy: 0.9701 - val_loss: 0.0259 - val_accuracy: 0.9640\n",
      "Epoch 107/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0251 - accuracy: 0.9672 - val_loss: 0.0252 - val_accuracy: 0.9640\n",
      "Epoch 108/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0257 - accuracy: 0.9665 - val_loss: 0.0310 - val_accuracy: 0.9620\n",
      "Epoch 109/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0240 - accuracy: 0.9696 - val_loss: 0.0286 - val_accuracy: 0.9640\n",
      "Epoch 110/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0242 - accuracy: 0.9696 - val_loss: 0.0297 - val_accuracy: 0.9620\n",
      "Epoch 111/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0243 - accuracy: 0.9693 - val_loss: 0.0307 - val_accuracy: 0.9680\n",
      "Epoch 112/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0238 - accuracy: 0.9717 - val_loss: 0.0288 - val_accuracy: 0.9660\n",
      "Epoch 113/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0266 - accuracy: 0.9655 - val_loss: 0.0258 - val_accuracy: 0.9700\n",
      "Epoch 114/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0244 - accuracy: 0.9703 - val_loss: 0.0312 - val_accuracy: 0.9600\n",
      "Epoch 115/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0247 - accuracy: 0.9696 - val_loss: 0.0244 - val_accuracy: 0.9740\n",
      "Epoch 116/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0235 - accuracy: 0.9696 - val_loss: 0.0295 - val_accuracy: 0.9580\n",
      "Epoch 117/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0206 - accuracy: 0.9743 - val_loss: 0.0257 - val_accuracy: 0.9680\n",
      "Epoch 118/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0267 - accuracy: 0.9667 - val_loss: 0.0271 - val_accuracy: 0.9680\n",
      "Epoch 119/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0213 - accuracy: 0.9729 - val_loss: 0.0242 - val_accuracy: 0.9740\n",
      "Epoch 120/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0272 - accuracy: 0.9660 - val_loss: 0.0278 - val_accuracy: 0.9680\n",
      "Epoch 121/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0253 - accuracy: 0.9684 - val_loss: 0.0244 - val_accuracy: 0.9720\n",
      "Epoch 122/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0231 - accuracy: 0.9710 - val_loss: 0.0322 - val_accuracy: 0.9580\n",
      "Epoch 123/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0302 - accuracy: 0.9615 - val_loss: 0.0626 - val_accuracy: 0.9200\n",
      "Epoch 124/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0267 - accuracy: 0.9655 - val_loss: 0.0268 - val_accuracy: 0.9700\n",
      "Epoch 125/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0259 - accuracy: 0.9689 - val_loss: 0.0269 - val_accuracy: 0.9700\n",
      "Epoch 126/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0211 - accuracy: 0.9755 - val_loss: 0.0272 - val_accuracy: 0.9680\n",
      "Epoch 127/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0334 - accuracy: 0.9594 - val_loss: 0.0250 - val_accuracy: 0.9660\n",
      "Epoch 128/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0233 - accuracy: 0.9705 - val_loss: 0.0256 - val_accuracy: 0.9700\n",
      "Epoch 129/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0246 - accuracy: 0.9691 - val_loss: 0.0275 - val_accuracy: 0.9700\n",
      "Epoch 130/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0237 - accuracy: 0.9712 - val_loss: 0.0248 - val_accuracy: 0.9680\n",
      "Epoch 131/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0233 - accuracy: 0.9715 - val_loss: 0.0325 - val_accuracy: 0.9540\n",
      "Epoch 132/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0245 - accuracy: 0.9689 - val_loss: 0.0267 - val_accuracy: 0.9700\n",
      "Epoch 133/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0221 - accuracy: 0.9731 - val_loss: 0.0339 - val_accuracy: 0.9560\n",
      "Epoch 134/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0283 - accuracy: 0.9629 - val_loss: 0.0318 - val_accuracy: 0.9640\n",
      "Epoch 135/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0218 - accuracy: 0.9734 - val_loss: 0.0275 - val_accuracy: 0.9680\n",
      "Epoch 136/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0264 - accuracy: 0.9620 - val_loss: 0.0259 - val_accuracy: 0.9700\n",
      "Epoch 137/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0233 - accuracy: 0.9698 - val_loss: 0.0308 - val_accuracy: 0.9640\n",
      "Epoch 138/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0250 - accuracy: 0.9653 - val_loss: 0.0284 - val_accuracy: 0.9680\n",
      "Epoch 139/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0261 - accuracy: 0.9629 - val_loss: 0.0276 - val_accuracy: 0.9600\n",
      "Epoch 140/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0226 - accuracy: 0.9712 - val_loss: 0.0305 - val_accuracy: 0.9620\n",
      "Epoch 141/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0234 - accuracy: 0.9708 - val_loss: 0.0259 - val_accuracy: 0.9700\n",
      "Epoch 142/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0259 - accuracy: 0.9682 - val_loss: 0.0373 - val_accuracy: 0.9520\n",
      "Epoch 143/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0274 - accuracy: 0.9665 - val_loss: 0.0294 - val_accuracy: 0.9640\n",
      "Epoch 144/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0271 - accuracy: 0.9658 - val_loss: 0.0334 - val_accuracy: 0.9600\n",
      "Epoch 145/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0232 - accuracy: 0.9712 - val_loss: 0.0362 - val_accuracy: 0.9580\n",
      "Epoch 146/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0255 - accuracy: 0.9682 - val_loss: 0.0250 - val_accuracy: 0.9720\n",
      "Epoch 147/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0253 - accuracy: 0.9689 - val_loss: 0.0312 - val_accuracy: 0.9620\n",
      "Epoch 148/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0238 - accuracy: 0.9701 - val_loss: 0.0296 - val_accuracy: 0.9660\n",
      "Epoch 149/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0256 - accuracy: 0.9660 - val_loss: 0.0311 - val_accuracy: 0.9560\n",
      "Epoch 150/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0248 - accuracy: 0.9691 - val_loss: 0.0354 - val_accuracy: 0.9580\n",
      "Epoch 151/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0201 - accuracy: 0.9765 - val_loss: 0.0262 - val_accuracy: 0.9600\n",
      "Epoch 152/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0245 - accuracy: 0.9682 - val_loss: 0.0251 - val_accuracy: 0.9720\n",
      "Epoch 153/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0186 - accuracy: 0.9774 - val_loss: 0.0259 - val_accuracy: 0.9720\n",
      "Epoch 154/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0209 - accuracy: 0.9758 - val_loss: 0.0275 - val_accuracy: 0.9700\n",
      "Epoch 155/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0243 - accuracy: 0.9703 - val_loss: 0.0286 - val_accuracy: 0.9600\n",
      "Epoch 156/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0232 - accuracy: 0.9698 - val_loss: 0.0267 - val_accuracy: 0.9640\n",
      "Epoch 157/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0226 - accuracy: 0.9722 - val_loss: 0.0247 - val_accuracy: 0.9640\n",
      "Epoch 158/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0226 - accuracy: 0.9717 - val_loss: 0.0255 - val_accuracy: 0.9760\n",
      "Epoch 159/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0219 - accuracy: 0.9717 - val_loss: 0.0316 - val_accuracy: 0.9580\n",
      "Epoch 160/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0234 - accuracy: 0.9684 - val_loss: 0.0318 - val_accuracy: 0.9600\n",
      "Epoch 161/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0241 - accuracy: 0.9689 - val_loss: 0.0288 - val_accuracy: 0.9620\n",
      "Epoch 162/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0244 - accuracy: 0.9693 - val_loss: 0.0281 - val_accuracy: 0.9640\n",
      "Epoch 163/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0207 - accuracy: 0.9722 - val_loss: 0.0316 - val_accuracy: 0.9600\n",
      "Epoch 164/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0198 - accuracy: 0.9758 - val_loss: 0.0223 - val_accuracy: 0.9740\n",
      "Epoch 165/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0207 - accuracy: 0.9734 - val_loss: 0.0230 - val_accuracy: 0.9740\n",
      "Epoch 166/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0200 - accuracy: 0.9743 - val_loss: 0.0333 - val_accuracy: 0.9580\n",
      "Epoch 167/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0280 - accuracy: 0.9648 - val_loss: 0.0255 - val_accuracy: 0.9720\n",
      "Epoch 168/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0199 - accuracy: 0.9748 - val_loss: 0.0288 - val_accuracy: 0.9580\n",
      "Epoch 169/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0191 - accuracy: 0.9772 - val_loss: 0.0321 - val_accuracy: 0.9620\n",
      "Epoch 170/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0242 - accuracy: 0.9696 - val_loss: 0.0243 - val_accuracy: 0.9740\n",
      "Epoch 171/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0201 - accuracy: 0.9748 - val_loss: 0.0258 - val_accuracy: 0.9660\n",
      "Epoch 172/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0212 - accuracy: 0.9727 - val_loss: 0.0292 - val_accuracy: 0.9540\n",
      "Epoch 173/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0279 - accuracy: 0.9648 - val_loss: 0.0228 - val_accuracy: 0.9680\n",
      "Epoch 174/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0229 - accuracy: 0.9705 - val_loss: 0.0258 - val_accuracy: 0.9660\n",
      "Epoch 175/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0224 - accuracy: 0.9734 - val_loss: 0.0494 - val_accuracy: 0.9520\n",
      "Epoch 176/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0235 - accuracy: 0.9686 - val_loss: 0.0340 - val_accuracy: 0.9640\n",
      "Epoch 177/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0244 - accuracy: 0.9701 - val_loss: 0.0251 - val_accuracy: 0.9720\n",
      "Epoch 178/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0216 - accuracy: 0.9736 - val_loss: 0.0293 - val_accuracy: 0.9600\n",
      "Epoch 179/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0240 - accuracy: 0.9701 - val_loss: 0.0311 - val_accuracy: 0.9620\n",
      "Epoch 180/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0217 - accuracy: 0.9734 - val_loss: 0.0261 - val_accuracy: 0.9660\n",
      "Epoch 181/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0268 - accuracy: 0.9665 - val_loss: 0.0262 - val_accuracy: 0.9720\n",
      "Epoch 182/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0194 - accuracy: 0.9729 - val_loss: 0.0226 - val_accuracy: 0.9680\n",
      "Epoch 183/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0208 - accuracy: 0.9736 - val_loss: 0.0266 - val_accuracy: 0.9740\n",
      "Epoch 184/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0203 - accuracy: 0.9746 - val_loss: 0.0253 - val_accuracy: 0.9660\n",
      "Epoch 185/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0208 - accuracy: 0.9736 - val_loss: 0.0242 - val_accuracy: 0.9720\n",
      "Epoch 186/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0233 - accuracy: 0.9693 - val_loss: 0.0269 - val_accuracy: 0.9640\n",
      "Epoch 187/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0207 - accuracy: 0.9739 - val_loss: 0.0257 - val_accuracy: 0.9720\n",
      "Epoch 188/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0218 - accuracy: 0.9743 - val_loss: 0.0325 - val_accuracy: 0.9600\n",
      "Epoch 189/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0259 - accuracy: 0.9674 - val_loss: 0.0309 - val_accuracy: 0.9680\n",
      "Epoch 190/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0215 - accuracy: 0.9722 - val_loss: 0.0274 - val_accuracy: 0.9720\n",
      "Epoch 191/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0190 - accuracy: 0.9731 - val_loss: 0.0244 - val_accuracy: 0.9740\n",
      "Epoch 192/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0223 - accuracy: 0.9722 - val_loss: 0.0253 - val_accuracy: 0.9660\n",
      "Epoch 193/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0207 - accuracy: 0.9748 - val_loss: 0.0297 - val_accuracy: 0.9640\n",
      "Epoch 194/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0190 - accuracy: 0.9758 - val_loss: 0.0229 - val_accuracy: 0.9700\n",
      "Epoch 195/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0207 - accuracy: 0.9736 - val_loss: 0.0267 - val_accuracy: 0.9640\n",
      "Epoch 196/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0247 - accuracy: 0.9667 - val_loss: 0.0283 - val_accuracy: 0.9700\n",
      "Epoch 197/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0244 - accuracy: 0.9703 - val_loss: 0.0261 - val_accuracy: 0.9720\n",
      "Epoch 198/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0221 - accuracy: 0.9727 - val_loss: 0.0296 - val_accuracy: 0.9600\n",
      "Epoch 199/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0239 - accuracy: 0.9701 - val_loss: 0.0279 - val_accuracy: 0.9680\n",
      "Epoch 200/200\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0220 - accuracy: 0.9736 - val_loss: 0.0296 - val_accuracy: 0.9620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a83cf54280>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn3 = create_cnn3_model()\n",
    "cnn3.fit(x_tensor_train, x_train_labels, epochs=200,\n",
    "                    validation_data=(x_tensor_valid, x_valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0213365126401186, 0.9751908183097839]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn3.evaluate(test_tensor, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ultimo modello che si testa cerca di simulare il comportamento di un Inception Block. Quindi ci sono i primi quattro modelli ch1, ch2, ch3 e ch4 che corrispondono ai 4 flussi paralleli dell'Inception Block. Il quinto modello, rest, riceve in input la concatenazione degli output dei quattro modelli iniziali. \n",
    "Per la struttura di rest, sono stati anche testati dei livelli convoluzionali seguiti da livelli dense, che però non hanno migliorato le prestazioni in modo significativo, per tanto la versione finale presenta solo livelli dense.\n",
    "Anche per il numero di filtri e il padding utilizzato nei livelli convoluzionali dei 4 modelli iniziali sono stati testati differenti valori ma i migliori sono quelli riportati nella cella sottostante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "132/132 [==============================] - 2s 7ms/step - loss: 0.0669 - accuracy: 0.5582 - val_loss: 0.0378 - val_accuracy: 0.8560\n",
      "Epoch 2/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0308 - accuracy: 0.8743 - val_loss: 0.0266 - val_accuracy: 0.8760\n",
      "Epoch 3/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0211 - accuracy: 0.9240 - val_loss: 0.0245 - val_accuracy: 0.9240\n",
      "Epoch 4/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0185 - accuracy: 0.9282 - val_loss: 0.0244 - val_accuracy: 0.9360\n",
      "Epoch 5/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0179 - accuracy: 0.9339 - val_loss: 0.0173 - val_accuracy: 0.9220\n",
      "Epoch 6/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0160 - accuracy: 0.9404 - val_loss: 0.0175 - val_accuracy: 0.9280\n",
      "Epoch 7/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0153 - accuracy: 0.9442 - val_loss: 0.0173 - val_accuracy: 0.9340\n",
      "Epoch 8/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0115 - accuracy: 0.9582 - val_loss: 0.0171 - val_accuracy: 0.9360\n",
      "Epoch 9/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0126 - accuracy: 0.9548 - val_loss: 0.0154 - val_accuracy: 0.9380\n",
      "Epoch 10/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.9646 - val_loss: 0.0152 - val_accuracy: 0.9580\n",
      "Epoch 11/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0107 - accuracy: 0.9620 - val_loss: 0.0160 - val_accuracy: 0.9560\n",
      "Epoch 12/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.9648 - val_loss: 0.0153 - val_accuracy: 0.9440\n",
      "Epoch 13/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.9684 - val_loss: 0.0167 - val_accuracy: 0.9380\n",
      "Epoch 14/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0109 - accuracy: 0.9603 - val_loss: 0.0144 - val_accuracy: 0.9320\n",
      "Epoch 15/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0103 - accuracy: 0.9591 - val_loss: 0.0173 - val_accuracy: 0.9560\n",
      "Epoch 16/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.9712 - val_loss: 0.0120 - val_accuracy: 0.9620\n",
      "Epoch 17/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.9736 - val_loss: 0.0162 - val_accuracy: 0.9600\n",
      "Epoch 18/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.9741 - val_loss: 0.0139 - val_accuracy: 0.9520\n",
      "Epoch 19/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0060 - accuracy: 0.9748 - val_loss: 0.0116 - val_accuracy: 0.9580\n",
      "Epoch 20/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0058 - accuracy: 0.9746 - val_loss: 0.0128 - val_accuracy: 0.9560\n",
      "Epoch 21/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0048 - accuracy: 0.9805 - val_loss: 0.0172 - val_accuracy: 0.9620\n",
      "Epoch 22/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 0.9815 - val_loss: 0.0135 - val_accuracy: 0.9700\n",
      "Epoch 23/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 0.9848 - val_loss: 0.0136 - val_accuracy: 0.9420\n",
      "Epoch 24/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0047 - accuracy: 0.9838 - val_loss: 0.0210 - val_accuracy: 0.9540\n",
      "Epoch 25/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 0.9850 - val_loss: 0.0306 - val_accuracy: 0.9600\n",
      "Epoch 26/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 0.9881 - val_loss: 0.0136 - val_accuracy: 0.9620\n",
      "Epoch 27/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0040 - accuracy: 0.9855 - val_loss: 0.0163 - val_accuracy: 0.9580\n",
      "Epoch 28/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9865 - val_loss: 0.0310 - val_accuracy: 0.9600\n",
      "Epoch 29/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0026 - accuracy: 0.9891 - val_loss: 0.0185 - val_accuracy: 0.9560\n",
      "Epoch 30/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 0.9860 - val_loss: 0.0138 - val_accuracy: 0.9560\n",
      "Epoch 31/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9886 - val_loss: 0.0309 - val_accuracy: 0.9540\n",
      "Epoch 32/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 0.9855 - val_loss: 0.0232 - val_accuracy: 0.9540\n",
      "Epoch 33/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9905 - val_loss: 0.0211 - val_accuracy: 0.9620\n",
      "Epoch 34/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 0.9943 - val_loss: 0.0468 - val_accuracy: 0.9560\n",
      "Epoch 35/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0040 - accuracy: 0.9865 - val_loss: 0.0200 - val_accuracy: 0.9600\n",
      "Epoch 36/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0022 - accuracy: 0.9907 - val_loss: 0.0277 - val_accuracy: 0.9660\n",
      "Epoch 37/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0036 - accuracy: 0.9893 - val_loss: 0.0157 - val_accuracy: 0.9500\n",
      "Epoch 38/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0035 - accuracy: 0.9860 - val_loss: 0.0176 - val_accuracy: 0.9580\n",
      "Epoch 39/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0031 - accuracy: 0.9869 - val_loss: 0.0206 - val_accuracy: 0.9620\n",
      "Epoch 40/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 8.9942e-04 - accuracy: 0.9957 - val_loss: 0.0262 - val_accuracy: 0.9660\n",
      "Epoch 41/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0029 - accuracy: 0.9907 - val_loss: 0.0251 - val_accuracy: 0.9620\n",
      "Epoch 42/300\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 0.0020 - accuracy: 0.9910 - val_loss: 0.0322 - val_accuracy: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a8210d8850>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Concatenate, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_channel_1():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    #input 28x28\n",
    "    model.add(tf.keras.layers.Conv2D(filters=3, kernel_size=1, activation='relu'))\n",
    "    #output 28x28\n",
    "    return model\n",
    "\n",
    "def create_channel_2():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    #input 28x28\n",
    "    model.add(tf.keras.layers.Conv2D(filters=3, kernel_size=1, activation='relu', input_shape=(28, 28, 1)))\n",
    "    #output 28x28\n",
    "    model.add(tf.keras.layers.Conv2D(filters=3, kernel_size=3, activation='relu', padding='same'))\n",
    "    #output 28x28\n",
    "    return model\n",
    "\n",
    "def create_channel_3():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    #input 28x28\n",
    "    model.add(tf.keras.layers.Conv2D(filters=3, kernel_size=1, activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
    "    #output 28x28\n",
    "    model.add(tf.keras.layers.Conv2D(filters=3, kernel_size=5, activation='relu', padding='same'))\n",
    "    #output 28x28\n",
    "    return model\n",
    "\n",
    "def create_channel_4():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    #input 28x28\n",
    "    model.add(tf.keras.layers.Conv2D(filters=3, kernel_size=3, activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
    "    #output 28x28\n",
    "    model.add(tf.keras.layers.Conv2D(filters=3, kernel_size=1, activation='relu', padding='same'))\n",
    "    #output 28x28\n",
    "    return model\n",
    "\n",
    "ch1 = create_channel_1()\n",
    "ch2 = create_channel_2()\n",
    "ch3 = create_channel_3()\n",
    "ch4 = create_channel_4()\n",
    "\n",
    "input1 = Input(shape=(28, 28, 1))\n",
    "input2 = Input(shape=(28, 28, 1))\n",
    "input3 = Input(shape=(28, 28, 1))\n",
    "input4 = Input(shape=(28, 28, 1))\n",
    "\n",
    "output1 = ch1(input1)\n",
    "output2 = ch2(input2)\n",
    "output3 = ch3(input3)\n",
    "output4 = ch4(input4)\n",
    "\n",
    "concatenated = tf.concat([output1, output2, output3, output4], axis=3)\n",
    "\n",
    "def model_post_inception():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(28, 28, 12)))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "rest = model_post_inception()\n",
    "final_output = rest(concatenated)\n",
    "\n",
    "final_model = Model(inputs=[input1, input2, input3, input4], outputs=final_output)\n",
    "\n",
    "final_model.compile(optimizer='adam', loss=tfa.losses.sigmoid_focal_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "final_model.fit([x_tensor_train, x_tensor_train, x_tensor_train, x_tensor_train], \n",
    "                x_train_labels, epochs=300,\n",
    "                    validation_data=([x_tensor_valid, x_tensor_valid, x_tensor_valid, x_tensor_valid], \n",
    "                                     x_valid_labels),\n",
    "          callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0237 - accuracy: 0.9714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.023670228198170662, 0.9713740348815918]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.evaluate([test_tensor, test_tensor, test_tensor, test_tensor], test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa cella si stampa l'immagine del modello che simula un Inception Block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "import pydot\n",
    "\n",
    "plot_model(final_model, to_file='model_represent.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "img = plt.imread('model_represent.png')\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nella cella sottostante si è implementata una classe per calcolare i valori delle metriche precision, recall, f1 score e anche ottenere la confusion matrix.\n",
    "Per il calcolo di questi valori è necessario applicare una threshold per ottenere le etichette delle predizioni. Come threshold si è scelto il valore 0.5 poichè dalla documentazione si evince che è la stessa threshold utilizzata dalla funzione sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "class ModelEval:\n",
    "    def __init__(self, model, isTensor):\n",
    "        self.model = model\n",
    "        if(isTensor):\n",
    "            self.predictions = self.model.predict(test_tensor)  \n",
    "        else:\n",
    "            self.predictions = self.model.predict(test_images)\n",
    "    \n",
    "        self.y_pred = (self.predictions > 0.5).astype(\"int32\")\n",
    "        self.prec = 0\n",
    "        self.rec = 0\n",
    "        self.f1 = 0\n",
    "    \n",
    "    def calculate_precision(self):\n",
    "        self.prec = precision_score(test_labels, self.y_pred)\n",
    "        print(\"Precision:\",self.prec)\n",
    "\n",
    "    def calculate_recall(self):\n",
    "        self.rec = recall_score(test_labels, self.y_pred)\n",
    "        print(\"Recall:\",self.rec)\n",
    "\n",
    "    def calculate_f1(self):\n",
    "        self.f1 = f1_score(test_labels, self.y_pred)\n",
    "        print(\"F1 Score:\",self.f1)\n",
    "\n",
    "    def print_confusion_matrix(self):\n",
    "        cm = confusion_matrix(test_labels, self.y_pred)\n",
    "        plt.figure(figsize=(4, 2))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.xlabel(\"Predicted labels\")\n",
    "        plt.ylabel(\"True labels\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I modelli addestrati e i loro valori di accuracy e loss su test set sono i seguenti:\n",
    "\n",
    "fnn_drop   loss: 0.1005 - accuracy: 0.9637\n",
    "\n",
    "last_fnn   loss: 0.1156 - accuracy: 0.9637\n",
    "\n",
    "lenet2   loss: 0.0778 - accuracy: 0.9790\n",
    "\n",
    "cnn1   loss: 0.0209 - accuracy: 0.9733\n",
    "\n",
    "cnn2   loss: 0.0067 - accuracy: 0.9790\n",
    "\n",
    "cnn3   loss: 0.0213 - accuracy: 0.9752\n",
    "\n",
    "final_model   loss: 0.0237 - accuracy: 0.9714\n",
    "\n",
    "Possiamo notare come le reti CNN hanno ottenuto risultati migliori sia su accuracy sia su loss rispetto alle reti FNN.\n",
    "I migliori modelli sono lenet2 e cnn2.\n",
    "\n",
    "Di seguito si riportano i valori di precision, recall e f1 score dei due modelli migliori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lenet2 results\n",
      "Precision: 0.9900249376558603\n",
      "Recall: 0.9826732673267327\n",
      "F1 Score: 0.986335403726708\n",
      "\n",
      "cnn2 results\n",
      "Precision: 0.9924812030075187\n",
      "Recall: 0.9801980198019802\n",
      "F1 Score: 0.9863013698630136\n"
     ]
    }
   ],
   "source": [
    "eval_lenet2 = ModelEval(lenet2,True)\n",
    "print(\"\\nlenet2 results\")\n",
    "eval_lenet2.calculate_precision()\n",
    "eval_lenet2.calculate_recall()\n",
    "eval_lenet2.calculate_f1()\n",
    "print(\"\\ncnn2 results\")\n",
    "eval_cnn2 = ModelEval(cnn2,True)\n",
    "eval_cnn2.calculate_precision()\n",
    "eval_cnn2.calculate_recall()\n",
    "eval_cnn2.calculate_f1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix per il modello lenet2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix per il modello cnn2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAokAAAIhCAYAAAAimCCiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABFJ0lEQVR4nO3de5iN9f7/8deaMbOcZiZjzCnnY5gRhhjlfJxySoXs2tQkIjUb6Ytv0cnguzOS0EFGpGFXI4r5IlFCDVFIdocRdjMNcsgYc3L//vC1fq0+aBazrGE9H9d1X5d13591r/da19W+3vv1+dyfsVmWZQkAAAD4Ax9PFwAAAIDShyYRAAAABppEAAAAGGgSAQAAYKBJBAAAgIEmEQAAAAaaRAAAABhoEgEAAGCgSQQAAICBJhG4BnzzzTd64IEHVKtWLZUtW1YVK1ZU8+bNNX36dP32229u/ewdO3aoffv2CgoKks1m08yZM0v8M2w2myZPnlzi9/0rycnJstlsstls2rBhg3HdsizVrVtXNptNHTp0uKzPmDNnjpKTk116z4YNGy5aEwBcLWU8XQCAS3v99dc1YsQINWjQQE888YQaNWqkgoICbdu2TfPmzdOWLVuUmprqts9/8MEHlZOTo5SUFFWqVEk1a9Ys8c/YsmWLqlatWuL3La6AgADNnz/faAQ3btyoH3/8UQEBAZd97zlz5igkJERDhgwp9nuaN2+uLVu2qFGjRpf9uQBwpWgSgVJsy5YteuSRR9S1a1ctX75cdrvdca1r164aM2aM0tLS3FrD7t27NXToUMXFxbntM1q3bu22exfHgAED9Pbbb+uVV15RYGCg4/z8+fMVGxurkydPXpU6CgoKZLPZFBgY6PHfBACYbgZKsSlTpshms+m1115zahDP8/f3V+/evR2vz549q+nTp+umm26S3W5XaGio/v73v+vQoUNO7+vQoYOioqKUnp6utm3bqnz58qpdu7amTp2qs2fPSvr/U7GFhYWaO3euY1pWkiZPnuz49x+df8/+/fsd59avX68OHTqocuXKKleunKpXr6677rpLp0+fdoy50HTz7t271adPH1WqVElly5ZV06ZNtXDhQqcx56dl33nnHU2cOFGRkZEKDAxUly5dtG/fvuL9yJLuvfdeSdI777zjOHfixAm99957evDBBy/4nmeeeUatWrVScHCwAgMD1bx5c82fP1+WZTnG1KxZU3v27NHGjRsdv9/5JPZ87YsWLdKYMWN04403ym6364cffjCmm48cOaJq1aqpTZs2KigocNz/22+/VYUKFXT//fcX+7sCQHHRJAKlVFFRkdavX6+YmBhVq1atWO955JFH9OSTT6pr165asWKFnnvuOaWlpalNmzY6cuSI09isrCz97W9/03333acVK1YoLi5O48eP1+LFiyVJd9xxh7Zs2SJJuvvuu7VlyxbH6+Lav3+/7rjjDvn7++vNN99UWlqapk6dqgoVKig/P/+i79u3b5/atGmjPXv2aNasWXr//ffVqFEjDRkyRNOnTzfGT5gwQT///LPeeOMNvfbaa/r+++/Vq1cvFRUVFavOwMBA3X333XrzzTcd59555x35+PhowIABF/1uw4YN07Jly/T++++rX79+GjVqlJ577jnHmNTUVNWuXVvNmjVz/H5/Xhowfvx4HThwQPPmzdPKlSsVGhpqfFZISIhSUlKUnp6uJ598UpJ0+vRp3XPPPapevbrmzZtXrO8JAC6xAJRKWVlZliRr4MCBxRq/d+9eS5I1YsQIp/NffPGFJcmaMGGC41z79u0tSdYXX3zhNLZRo0ZW9+7dnc5JskaOHOl0btKkSdaF/udjwYIFliQrIyPDsizLevfddy1J1s6dOy9ZuyRr0qRJjtcDBw607Ha7deDAAadxcXFxVvny5a3jx49blmVZn3zyiSXJuv32253GLVu2zJJkbdmy5ZKfe77e9PR0x712795tWZZltWzZ0hoyZIhlWZbVuHFjq3379he9T1FRkVVQUGA9++yzVuXKla2zZ886rl3svec/r127dhe99sknnzidnzZtmiXJSk1NtQYPHmyVK1fO+uabby75HQHgcpEkAteJTz75RJKMByRuueUWNWzYUB9//LHT+fDwcN1yyy1O55o0aaKff/65xGpq2rSp/P399fDDD2vhwoX66aefivW+9evXq3PnzkaCOmTIEJ0+fdpINP845S6d+x6SXPou7du3V506dfTmm29q165dSk9Pv+hU8/kau3TpoqCgIPn6+srPz09PP/20jh49quzs7GJ/7l133VXssU888YTuuOMO3XvvvVq4cKFefvllRUdHF/v9AOAKmkSglAoJCVH58uWVkZFRrPFHjx6VJEVERBjXIiMjHdfPq1y5sjHObrcrNzf3Mqq9sDp16mjdunUKDQ3VyJEjVadOHdWpU0cvvfTSJd939OjRi36P89f/6M/f5fz6TVe+i81m0wMPPKDFixdr3rx5ql+/vtq2bXvBsV9++aW6desm6dzT559//rnS09M1ceJElz/3Qt/zUjUOGTJEZ86cUXh4OGsRAbgVTSJQSvn6+qpz587avn278eDJhZxvlDIzM41rv/zyi0JCQkqstrJly0qS8vLynM7/ed2jJLVt21YrV67UiRMntHXrVsXGxiohIUEpKSkXvX/lypUv+j0kleh3+aMhQ4boyJEjmjdvnh544IGLjktJSZGfn58+/PBD9e/fX23atFGLFi0u6zMv9ADQxWRmZmrkyJFq2rSpjh49qrFjx17WZwJAcdAkAqXY+PHjZVmWhg4desEHPQoKCrRy5UpJUqdOnSTJ8eDJeenp6dq7d686d+5cYnWdf0L3m2++cTp/vpYL8fX1VatWrfTKK69Ikr766quLju3cubPWr1/vaArPe+utt1S+fHm3bQ9z44036oknnlCvXr00ePDgi46z2WwqU6aMfH19Hedyc3O1aNEiY2xJpbNFRUW69957ZbPZtHr1aiUmJurll1/W+++/f8X3BoALYZ9EoBSLjY3V3LlzNWLECMXExOiRRx5R48aNVVBQoB07dui1115TVFSUevXqpQYNGujhhx/Wyy+/LB8fH8XFxWn//v166qmnVK1aNf3jH/8osbpuv/12BQcHKz4+Xs8++6zKlCmj5ORkHTx40GncvHnztH79et1xxx2qXr26zpw543iCuEuXLhe9/6RJk/Thhx+qY8eOevrppxUcHKy3335bH330kaZPn66goKAS+y5/NnXq1L8cc8cdd2jGjBkaNGiQHn74YR09elT//Oc/L7hNUXR0tFJSUrR06VLVrl1bZcuWvax1hJMmTdJnn32mNWvWKDw8XGPGjNHGjRsVHx+vZs2aqVatWi7fEwAuhSYRKOWGDh2qW265RUlJSZo2bZqysrLk5+en+vXra9CgQXr00UcdY+fOnas6depo/vz5euWVVxQUFKQePXooMTHxgmsQL1dgYKDS0tKUkJCg++67TzfccIMeeughxcXF6aGHHnKMa9q0qdasWaNJkyYpKytLFStWVFRUlFasWOFY03chDRo00ObNmzVhwgSNHDlSubm5atiwoRYsWODSXy5xl06dOunNN9/UtGnT1KtXL914440aOnSoQkNDFR8f7zT2mWeeUWZmpoYOHarff/9dNWrUcNpHsjjWrl2rxMREPfXUU06JcHJyspo1a6YBAwZo06ZN8vf3L4mvBwCSJJtl/WHnVwAAAECsSQQAAMAF0CQCAADAQJMIAAAAA00iAAAADDSJAAAAMNAkAgAAwECTCAAAAMN1uZn2mr2HPV0CADdpV6+Kp0sA4CZlPdiVlGv26F8Puky5O2a77d7uRJIIAAAAw3WZJAIAALjERm72ZzSJAAAANpunKyh1aJsBAABgIEkEAABgutnALwIAAAADSSIAAABrEg0kiQAAADCQJAIAALAm0cAvAgAAAANJIgAAAGsSDTSJAAAATDcb+EUAAABgIEkEAABgutlAkggAAAADSSIAAABrEg38IgAAADCQJAIAALAm0UCSCAAAAANJIgAAAGsSDTSJAAAATDcbaJsBAABgIEkEAABgutnALwIAAAADSSIAAABJooFfBAAAAAaSRAAAAB+ebv4zkkQAAAAYSBIBAABYk2igSQQAAGAzbQNtMwAAAAwkiQAAAEw3G/hFAAAAYCBJBAAAYE2igSQRAAAABpJEAAAA1iQa+EUAAABgIEkEAABgTaKBJhEAAIDpZgO/CAAAAAwkiQAAAEw3G0gSAQAAYCBJBAAAYE2igV8EAAAABpJEAAAA1iQaSBIBAABgIEkEAABgTaKBJhEAAIAm0cAvAgAAAANNIgAAgM3mvsMFc+fOVZMmTRQYGKjAwEDFxsZq9erVjutDhgyRzWZzOlq3bu10j7y8PI0aNUohISGqUKGCevfurUOHDrn8k9AkAgAAlBJVq1bV1KlTtW3bNm3btk2dOnVSnz59tGfPHseYHj16KDMz03GsWrXK6R4JCQlKTU1VSkqKNm3apFOnTqlnz54qKipyqRbWJAIAAJSSNYm9evVyev3CCy9o7ty52rp1qxo3bixJstvtCg8Pv+D7T5w4ofnz52vRokXq0qWLJGnx4sWqVq2a1q1bp+7duxe7ltLxiwAAAFyn8vLydPLkSacjLy/vL99XVFSklJQU5eTkKDY21nF+w4YNCg0NVf369TV06FBlZ2c7rm3fvl0FBQXq1q2b41xkZKSioqK0efNml+qmSQQAAHDjmsTExEQFBQU5HYmJiRctZdeuXapYsaLsdruGDx+u1NRUNWrUSJIUFxent99+W+vXr9eLL76o9PR0derUydF0ZmVlyd/fX5UqVXK6Z1hYmLKyslz6SZhuBgAAcKPx48dr9OjRTufsdvtFxzdo0EA7d+7U8ePH9d5772nw4MHauHGjGjVqpAEDBjjGRUVFqUWLFqpRo4Y++ugj9evX76L3tCxLNhcfoqFJBAAAcOOaRLvdfsmm8M/8/f1Vt25dSVKLFi2Unp6ul156Sa+++qoxNiIiQjVq1ND3338vSQoPD1d+fr6OHTvmlCZmZ2erTZs2LtXNdDMAAEAp2QLnQizLuugaxqNHj+rgwYOKiIiQJMXExMjPz09r1651jMnMzNTu3btdbhJJEgEAAEqJCRMmKC4uTtWqVdPvv/+ulJQUbdiwQWlpaTp16pQmT56su+66SxEREdq/f78mTJigkJAQ3XnnnZKkoKAgxcfHa8yYMapcubKCg4M1duxYRUdHO552Li6aRAAA4PVcXa/nLr/++qvuv/9+ZWZmKigoSE2aNFFaWpq6du2q3Nxc7dq1S2+99ZaOHz+uiIgIdezYUUuXLlVAQIDjHklJSSpTpoz69++v3Nxcde7cWcnJyfL19XWpFptlWVZJf0FPW7P3sKdLAOAm7epV8XQJANykrAejq/J3vem2e59+70G33dudSBIBAIDXKy1JYmnCgysAAAAwkCQCAAAQJBpIEgEAAGAgSQQAAF6PNYkmmkQAAOD1aBJNTDcDAADAQJIIAAC8HkmiiSQRAAAABpJEAADg9UgSTSSJAAAAMJAkAgAAECQaSBIBAABgIEkEAABejzWJJpJEAAAAGEgSAQCA1yNJNNEkAgAAr0eTaGK6GQAAAAaSRAAA4PVIEk0kiQAAADCQJAIAABAkGkgSAQAAYCBJBAAAXo81iSaSRAAAABhIEgEAgNcjSTTRJAIAAK9Hk2hiuhkAAAAGkkQAAACCRANJIgAAAAwkiQAAwOuxJtFEkggAAAADSSIAAPB6JIkmkkQAAAAYSBIBAIDXI0k00SQCAACvR5NoYroZAAAABpJEAAAAgkQDSSIAAAAMJIkAAMDrsSbRRJIIAAAAA0kiAADweiSJJpJEAAAAGEgSAQCA1yNJNNEkAgAA0CMamG4GAACAgSQRAAB4PaabTSSJAAAAMJAkAgAAr0eSaCJJBAAAKCXmzp2rJk2aKDAwUIGBgYqNjdXq1asd1y3L0uTJkxUZGaly5cqpQ4cO2rNnj9M98vLyNGrUKIWEhKhChQrq3bu3Dh065HItJIkolX7Ys1Mfpy7RgR/36eSxo3rov6bo5tbtHNd3btmoz//3Ax38cZ9yfj+hJ2csUNXa9RzXj/6aqcnD7rngvR984lk1u7WT278DgMuzLGWJli19R7/85z+SpDp162nYIyN0W9v2Hq4M17PSkiRWrVpVU6dOVd26dSVJCxcuVJ8+fbRjxw41btxY06dP14wZM5ScnKz69evr+eefV9euXbVv3z4FBARIkhISErRy5UqlpKSocuXKGjNmjHr27Knt27fL19e32LXQJKJUyjuTqxtr1VWrzndo/rSJxvX8M7mq3TBazW7tqHdemWZcrxQSqhcWfOB07vM1K7QudYkaNW/ttroBXLnQsHA9/o+xqla9uiRp5QfL9fijI7X0vVTVrVvvL94NXNt69erl9PqFF17Q3LlztXXrVjVq1EgzZ87UxIkT1a9fP0nnmsiwsDAtWbJEw4YN04kTJzR//nwtWrRIXbp0kSQtXrxY1apV07p169S9e/di10KTiFKpcUysGsfEXvT6LR17SDqXGF6Ij6+vAitVdjr3zdZP1fzWTrKXK19yhQIocR06Oif9ox7/h5alvKNvvt5Jkwi3cWeSmJeXp7y8PKdzdrtddrv9ku8rKirSv/71L+Xk5Cg2NlYZGRnKyspSt27dnO7Tvn17bd68WcOGDdP27dtVUFDgNCYyMlJRUVHavHmzS02iR9ckHjp0SBMnTlTHjh3VsGFDNWrUSB07dtTEiRN18OBBT5aG68yBH77ToYzvFdu1p6dLAeCCoqIirV71kXJzT+vmm5t5uhxcz2zuOxITExUUFOR0JCYmXrSUXbt2qWLFirLb7Ro+fLhSU1PVqFEjZWVlSZLCwsKcxoeFhTmuZWVlyd/fX5UqVbromOLyWJK4adMmxcXFqVq1aurWrZu6desmy7KUnZ2t5cuX6+WXX9bq1at16623XvI+F+rO8/Pz5O9/6e4c3mXLug8VXrWmat8U7elSABTD9//ep/sHDVR+fp7Kly+vpFmvqM7/rdECrjXjx4/X6NGjnc5dKkVs0KCBdu7cqePHj+u9997T4MGDtXHjRsf1P6eelmX9ZRJanDF/5rEm8R//+IceeughJSUlXfR6QkKC0tPTL3mfxMREPfPMM07n7hsxVvc/Oq7EasW1LT8vT9s/Xafu/Qd7uhQAxVSzZi0te2+5fv/9pNatXaOnJjyp+cmLaRThNu6cbi7O1PIf+fv7Ox5cadGihdLT0/XSSy/pySeflHQuLYyIiHCMz87OdqSL4eHhys/P17Fjx5zSxOzsbLVp08aluj023bx7924NHz78oteHDRum3bt3/+V9xo8frxMnTjgdAx5+vCRLxTVu5+ZPlJ9/xrGOEUDp5+fvr+o1aqhxVLQe/8cY1W9wk95e/JanywI8wrIs5eXlqVatWgoPD9fatWsd1/Lz87Vx40ZHAxgTEyM/Pz+nMZmZmdq9e7fLTaLHksSIiAht3rxZDRo0uOD1LVu2OHXJF3Oh7tzfP+8io+GNtqz7UNEtb1NAUKW/HgygVLIsSwX5+Z4uA9ex0rIFzoQJExzL8X7//XelpKRow4YNSktLk81mU0JCgqZMmaJ69eqpXr16mjJlisqXL69BgwZJkoKCghQfH68xY8aocuXKCg4O1tixYxUdHe142rm4PNYkjh07VsOHD9f27dvVtWtXhYWFyWazKSsrS2vXrtUbb7yhmTNneqo8eFhe7mkdzvyP4/XR7Ewd+ul7lQ8IUHCVcOX8flLHDv+qE78dkST9+ssBSVJgpWCnp5oPZx7Sj99+reFP/c/V/QIALtusmTN0W9t2CgsP1+mcHKWtXqVt6V9qzqtveLo0wO1+/fVX3X///crMzFRQUJCaNGmitLQ0de3aVZI0btw45ebmasSIETp27JhatWqlNWvWOPZIlKSkpCSVKVNG/fv3V25urjp37qzk5GSX9kiUJJtlWVaJfjsXLF26VElJSdq+fbuKiookSb6+voqJidHo0aPVv3//y7rvmr2HS7JMeMD3u77SrKceM87f0jFO9z8+UVs/XqW3X55iXI8b8IBuvzfe8XrFoleVvuF/9czr78rHhz8wdD1oV6+Kp0uAm016aoK+3LpVhw9nq2JAgOrXb6AH4ocqts2lH2TEta+sBzfmqzt29V8Pukw//DPObfd2J482iecVFBToyJFziVBISIj8/Pyu6H40icD1iyYRuH7RJJYupWIzbT8/v2KtPwQAAHCH0rImsTQpFU0iAACAJ9EjmlikBQAAAANJIgAA8HpMN5tIEgEAAGAgSQQAAF6PINFEkggAAAADSSIAAPB6Pj5EiX9GkggAAAADSSIAAPB6rEk00SQCAACvxxY4JqabAQAAYCBJBAAAXo8g0USSCAAAAANJIgAA8HqsSTSRJAIAAMBAkggAALweSaKJJBEAAAAGkkQAAOD1CBJNNIkAAMDrMd1sYroZAAAABpJEAADg9QgSTSSJAAAAMJAkAgAAr8eaRBNJIgAAAAwkiQAAwOsRJJpIEgEAAGAgSQQAAF6PNYkmkkQAAAAYSBIBAIDXI0g00SQCAACvx3SzielmAAAAGEgSAQCA1yNINJEkAgAAwECSCAAAvB5rEk0kiQAAADCQJAIAAK9HkGgiSQQAAICBJBEAAHg91iSaaBIBAIDXo0c0Md0MAAAAA0kiAADwekw3m0gSAQAAYCBJBAAAXo8k0USSCAAAAANJIgAA8HoEiSaSRAAAgFIiMTFRLVu2VEBAgEJDQ9W3b1/t27fPacyQIUNks9mcjtatWzuNycvL06hRoxQSEqIKFSqod+/eOnTokEu10CQCAACv9+emqyQPV2zcuFEjR47U1q1btXbtWhUWFqpbt27KyclxGtejRw9lZmY6jlWrVjldT0hIUGpqqlJSUrRp0yadOnVKPXv2VFFRUbFrYboZAAB4vdIy3ZyWlub0esGCBQoNDdX27dvVrl07x3m73a7w8PAL3uPEiROaP3++Fi1apC5dukiSFi9erGrVqmndunXq3r17sWohSQQAAHCjvLw8nTx50unIy8sr1ntPnDghSQoODnY6v2HDBoWGhqp+/foaOnSosrOzHde2b9+ugoICdevWzXEuMjJSUVFR2rx5c7HrpkkEAABez53TzYmJiQoKCnI6EhMT/7Imy7I0evRo3XbbbYqKinKcj4uL09tvv63169frxRdfVHp6ujp16uRoPLOysuTv769KlSo53S8sLExZWVnF/k2YbgYAAHCj8ePHa/To0U7n7Hb7X77v0Ucf1TfffKNNmzY5nR8wYIDj31FRUWrRooVq1Kihjz76SP369bvo/SzLcmmNJE0iAADweu5ck2i324vVFP7RqFGjtGLFCn366aeqWrXqJcdGRESoRo0a+v777yVJ4eHhys/P17Fjx5zSxOzsbLVp06bYNTDdDAAAUEpYlqVHH31U77//vtavX69atWr95XuOHj2qgwcPKiIiQpIUExMjPz8/rV271jEmMzNTu3fvdqlJJEkEAABez6eUPN48cuRILVmyRB988IECAgIcawiDgoJUrlw5nTp1SpMnT9Zdd92liIgI7d+/XxMmTFBISIjuvPNOx9j4+HiNGTNGlStXVnBwsMaOHavo6GjH087FQZMIAABQSsydO1eS1KFDB6fzCxYs0JAhQ+Tr66tdu3bprbfe0vHjxxUREaGOHTtq6dKlCggIcIxPSkpSmTJl1L9/f+Xm5qpz585KTk6Wr69vsWuxWZZllci3KkXW7D3s6RIAuEm7elU8XQIANynrweiq2ytb3XbvNSNb//WgUogkEQAAeD1X/zKKN+DBFQAAABhIEgEAgNfzIUg0kCQCAADAQJIIAAC8HmsSTSSJAAAAMJAkAgAAr0eQaCJJBAAAgIEkEQAAeD2biBL/jCYRAAB4PbbAMTHdDAAAAANJIgAA8HpsgWMiSQQAAICBJBEAAHg9gkQTSSIAAAAMJIkAAMDr+RAlGkgSAQAAYLjiJrGoqEg7d+7UsWPHSqIeAACAq85mc99xrXK5SUxISND8+fMlnWsQ27dvr+bNm6tatWrasGFDSdcHAADgdjabzW3HtcrlJvHdd9/VzTffLElauXKlMjIy9N133ykhIUETJ04s8QIBAABw9bncJB45ckTh4eGSpFWrVumee+5R/fr1FR8fr127dpV4gQAAAO7GdLPJ5SYxLCxM3377rYqKipSWlqYuXbpIkk6fPi1fX98SLxAAAABXn8tb4DzwwAPq37+/IiIiZLPZ1LVrV0nSF198oZtuuqnECwQAAHA3tsAxudwkTp48WVFRUTp48KDuuece2e12SZKvr6/+67/+q8QLBAAAwNV3WZtp33333ca5wYMHX3ExAAAAnkCOaCpWkzhr1qxi3/Cxxx677GIAAABQOhSrSUxKSirWzWw2G00iAAC45lzL+xm6S7GaxIyMDHfXAQAA4DE+9IiGy/6zfPn5+dq3b58KCwtLsh4AAACUAi43iadPn1Z8fLzKly+vxo0b68CBA5LOrUWcOnVqiRcIAADgbvxZPpPLTeL48eP19ddfa8OGDSpbtqzjfJcuXbR06dISLQ4AAACe4fIWOMuXL9fSpUvVunVrp+64UaNG+vHHH0u0OAAAgKvhGg783MblJPHw4cMKDQ01zufk5FzTkSoAAAD+P5ebxJYtW+qjjz5yvD7fGL7++uuKjY0tucoAAACuEtYkmlyebk5MTFSPHj307bffqrCwUC+99JL27NmjLVu2aOPGje6oEQAAAFeZy0limzZt9Pnnn+v06dOqU6eO1qxZo7CwMG3ZskUxMTHuqBEAAMCtfGzuO65Vl/W3m6Ojo7Vw4cKSrgUAAMAjruVpYXe5rCaxqKhIqamp2rt3r2w2mxo2bKg+ffqoTJnLuh0AAABKGZe7ut27d6tPnz7KyspSgwYNJEn//ve/VaVKFa1YsULR0dElXiQAAIA7kSOaXF6T+NBDD6lx48Y6dOiQvvrqK3311Vc6ePCgmjRpoocfftgdNQIAAOAqczlJ/Prrr7Vt2zZVqlTJca5SpUp64YUX1LJlyxItDgAA4GrwYU2iweUksUGDBvr111+N89nZ2apbt26JFAUAAADPKlaSePLkSce/p0yZoscee0yTJ09W69atJUlbt27Vs88+q2nTprmnSgAAADciSDQVq0m84YYbnB4NtyxL/fv3d5yzLEuS1KtXLxUVFbmhTAAAAFxNxWoSP/nkE3fXAQAA4DHsk2gqVpPYvn17d9cBAACAUuSyd78+ffq0Dhw4oPz8fKfzTZo0ueKiAAAAriaCRJPLTeLhw4f1wAMPaPXq1Re8zppEAABwrWELHJPLW+AkJCTo2LFj2rp1q8qVK6e0tDQtXLhQ9erV04oVK9xRIwAAgFdITExUy5YtFRAQoNDQUPXt21f79u1zGmNZliZPnqzIyEiVK1dOHTp00J49e5zG5OXladSoUQoJCVGFChXUu3dvHTp0yKVaXG4S169fr6SkJLVs2VI+Pj6qUaOG7rvvPk2fPl2JiYmu3g4AAMDjbDb3Ha7YuHGjRo4cqa1bt2rt2rUqLCxUt27dlJOT4xgzffp0zZgxQ7Nnz1Z6errCw8PVtWtX/f77744xCQkJSk1NVUpKijZt2qRTp06pZ8+eLs34ujzdnJOTo9DQUElScHCwDh8+rPr16ys6OlpfffWVq7cDAADA/0lLS3N6vWDBAoWGhmr79u1q166dLMvSzJkzNXHiRPXr10+StHDhQoWFhWnJkiUaNmyYTpw4ofnz52vRokXq0qWLJGnx4sWqVq2a1q1bp+7duxerlsv6iyvnY8+mTZvq1Vdf1X/+8x/NmzdPERERrt4OAADA42w2m9uOvLw8nTx50unIy8srVl0nTpyQdC6Yk6SMjAxlZWWpW7dujjF2u13t27fX5s2bJUnbt29XQUGB05jIyEhFRUU5xhTHZa1JzMzMlCRNmjRJaWlpql69umbNmqUpU6a4ejsAAIDrWmJiooKCgpyO4izRsyxLo0eP1m233aaoqChJUlZWliQpLCzMaWxYWJjjWlZWlvz9/VWpUqWLjikOl6eb//a3vzn+3axZM+3fv1/fffedqlevrpCQEFdv5xa31SkddQAoeZVaPurpEgC4Se6O2R77bJdTMxeMHz9eo0ePdjpnt9v/8n2PPvqovvnmG23atMm49ufNvy3L+ssNwYsz5o8ue5/E88qXL6/mzZtf6W0AAACuS3a7vVhN4R+NGjVKK1as0KeffqqqVas6zoeHh0s6lxb+cZlfdna2I10MDw9Xfn6+jh075pQmZmdnq02bNsWuoVhN4p+730uZMWNGsccCAACUBqXlz/JZlqVRo0YpNTVVGzZsUK1atZyu16pVS+Hh4Vq7dq2aNWsmScrPz9fGjRs1bdo0SVJMTIz8/Py0du1a9e/fX5KUmZmp3bt3a/r06cWupVhN4o4dO4p1s9LyAwMAALjCp5S0MCNHjtSSJUv0wQcfKCAgwLGGMCgoSOXKlZPNZlNCQoKmTJmievXqqV69epoyZYrKly+vQYMGOcbGx8drzJgxqly5soKDgzV27FhFR0c7nnYujmI1iZ988sllfE0AAAC4Yu7cuZKkDh06OJ1fsGCBhgwZIkkaN26ccnNzNWLECB07dkytWrXSmjVrFBAQ4BiflJSkMmXKqH///srNzVXnzp2VnJwsX1/fYtdisyzLuuJvVMqczr/uvhKA/1O51ShPlwDATTz54MroFd+57d4zet/ktnu7kzsf5gEAAMA16oqfbgYAALjW8VyFiSQRAAAABpJEAADg9UrL082lyWUliYsWLdKtt96qyMhI/fzzz5KkmTNn6oMPPijR4gAAAOAZLjeJc+fO1ejRo3X77bfr+PHjKioqkiTdcMMNmjlzZknXBwAA4HY2m/uOa5XLTeLLL7+s119/XRMnTnTaa6dFixbatWtXiRYHAABwNfjYbG47rlUuN4kZGRmOPwPzR3a7XTk5OSVSFAAAADzL5SaxVq1a2rlzp3F+9erVatSoUUnUBAAAcFX5uPG4Vrn8dPMTTzyhkSNH6syZM7IsS19++aXeeecdJSYm6o033nBHjQAAALjKXG4SH3jgARUWFmrcuHE6ffq0Bg0apBtvvFEvvfSSBg4c6I4aAQAA3OoaXjroNpe1T+LQoUM1dOhQHTlyRGfPnlVoaGhJ1wUAAAAPuqLNtENCQkqqDgAAAI+5lp9CdheXm8RatWpd8u8b/vTTT1dUEAAAADzP5SYxISHB6XVBQYF27NihtLQ0PfHEEyVVFwAAwFVDkGhyuUl8/PHHL3j+lVde0bZt2664IAAAgKuNv91sKrHte+Li4vTee++V1O0AAADgQVf04MofvfvuuwoODi6p2wEAAFw1PLhicrlJbNasmdODK5ZlKSsrS4cPH9acOXNKtDgAAAB4hstNYt++fZ1e+/j4qEqVKurQoYNuuummkqoLAADgqiFINLnUJBYWFqpmzZrq3r27wsPD3VUTAAAAPMylB1fKlCmjRx55RHl5ee6qBwAA4KrzsbnvuFa5/HRzq1attGPHDnfUAgAAgFLC5TWJI0aM0JgxY3To0CHFxMSoQoUKTtebNGlSYsUBAABcDTZdw5GfmxS7SXzwwQc1c+ZMDRgwQJL02GOPOa7ZbDZZliWbzaaioqKSrxIAAMCNruVpYXcpdpO4cOFCTZ06VRkZGe6sBwAAAKVAsZtEy7IkSTVq1HBbMQAAAJ5Akmhy6cEVG5sIAQAAeAWXHlypX7/+XzaKv/322xUVBAAAcLURhJlcahKfeeYZBQUFuasWAAAAlBIuNYkDBw5UaGiou2oBAADwCNYkmoq9JpEYFgAAwHu4/HQzAADA9YYszFTsJvHs2bPurAMAAMBjfOgSDS7/7WYAAABc/1z+280AAADXGx5cMZEkAgAAwECSCAAAvB5LEk0kiQAAADCQJAIAAK/nI6LEPyNJBAAAgIEkEQAAeD3WJJpoEgEAgNdjCxwT080AAAAwkCQCAACvx5/lM5EkAgAAwECSCAAAvB5BookkEQAAAAaaRAAA4PV8bDa3Ha769NNP1atXL0VGRspms2n58uVO14cMGSKbzeZ0tG7d2mlMXl6eRo0apZCQEFWoUEG9e/fWoUOHXPtNXK4cAAAAbpOTk6Obb75Zs2fPvuiYHj16KDMz03GsWrXK6XpCQoJSU1OVkpKiTZs26dSpU+rZs6eKioqKXQdrEgEAgNcrTWsS4+LiFBcXd8kxdrtd4eHhF7x24sQJzZ8/X4sWLVKXLl0kSYsXL1a1atW0bt06de/evVh1kCQCAACv5+PGIy8vTydPnnQ68vLyrqjeDRs2KDQ0VPXr19fQoUOVnZ3tuLZ9+3YVFBSoW7dujnORkZGKiorS5s2bi/0ZNIkAAABulJiYqKCgIKcjMTHxsu8XFxent99+W+vXr9eLL76o9PR0derUydF4ZmVlyd/fX5UqVXJ6X1hYmLKysor9OUw3AwAAr2dz43zz+PHjNXr0aKdzdrv9su83YMAAx7+joqLUokUL1ahRQx999JH69et30fdZluXS96RJBAAAcCO73X5FTeFfiYiIUI0aNfT9999LksLDw5Wfn69jx445pYnZ2dlq06ZNse/LdDMAAPB6Njce7nb06FEdPHhQERERkqSYmBj5+flp7dq1jjGZmZnavXu3S00iSSIAAEApcurUKf3www+O1xkZGdq5c6eCg4MVHBysyZMn66677lJERIT279+vCRMmKCQkRHfeeackKSgoSPHx8RozZowqV66s4OBgjR07VtHR0Y6nnYuDJhEAAHi9y9n02l22bdumjh07Ol6fX884ePBgzZ07V7t27dJbb72l48ePKyIiQh07dtTSpUsVEBDgeE9SUpLKlCmj/v37Kzc3V507d1ZycrJ8fX2LXYfNsiyr5L5W6XA6/7r7SgD+T+VWozxdAgA3yd1x8c2j3W3xdtf+Gokr7oup6rZ7uxNJIgAA8HqlJ0csPWgSAQCA1ytFs82lBk83AwAAwECSCAAAvJ47N9O+VpEkAgAAwECSCAAAvB6pmYnfBAAAAAaSRAAA4PVYk2giSQQAAICBJBEAAHg9ckQTSSIAAAAMJIkAAMDrsSbRRJMIAAC8HlOrJn4TAAAAGEgSAQCA12O62USSCAAAAANJIgAA8HrkiCaSRAAAABhIEgEAgNdjSaKJJBEAAAAGkkQAAOD1fFiVaKBJBAAAXo/pZhPTzQAAADCQJAIAAK9nY7rZQJIIAAAAA0kiAADweqxJNJEkAgAAwECSCAAAvB5b4JhIEgEAAGAgSQQAAF6PNYkmmkQAAOD1aBJNTDcDAADAQJIIAAC8Hptpm0gSAQAAYCBJBAAAXs+HINFAkggAAAADSSIAAPB6rEk0kSQCAADAQJIIAAC8HvskmmgSAQCA12O62cR0MwAAAAwkiQAAwOuxBY6JJBEAAAAGkkQAAOD1WJNoIkkEAACAgSQR16TCwkK9Ome2Vq1aqaNHjigkpIp69blTQ4c9Ih8f/r8PUFoNvec2Db27rWpEBkuS9v6UpSmvrdaaz7+VJIUGB+j5x/uoS2xDBVUsp01f/aDR0/+lHw8cdrpPqya1NHlkT7WMrqmCwiJ9s+8/6vPoHJ3JK7jq3wnXB7bAMdEk4pqU/OYbevdfKXr2hamqU6eu9uzZrclPTVBAQIAG3fd3T5cH4CL+8+txPfXyB/rxwBFJ0n29WulfSQ+r9cCp2vtTlpYlPayCwiLdk/CqTuac0WP3ddKqeaPUrN/zOn0mX9K5BvGD2SP0zwVrNHrav5RfWKQm9W/U2bOWJ78acN2hScQ16Zuvd6h9x85q266DJCnyxqpKW/2Rvt2z27OFAbikVZ86/zc6+ZWVGnrPbbqlSS0VFJ5Vqya11Pyu57X3pyxJ0uOJS3Xg46nqHxej5NQtkqTpY/ppTsoG/XPBWsd9/pw0Aq4iSDQxL4drUtNmMfryiy36eX+GJGnfvu+086uvdGvbdh6uDEBx+fjYdE/3GFUo568vvsmQ3f9cbnEmv9Ax5uxZS/kFhWrTtI4kqUqlirqlSS0d/u2UPkkerf3rpmjNG4+rTdPaHvkOuH742GxuO1z16aefqlevXoqMjJTNZtPy5cudrluWpcmTJysyMlLlypVThw4dtGfPHqcxeXl5GjVqlEJCQlShQgX17t1bhw4dcu03cbnyq+jgwYN68MEHLzkmLy9PJ0+edDry8vKuUoXwlAfih6pH3B26s/ftatksSvfec6cG3f93xd3e09OlAfgLjetG6vDnL+rEFzM1a+IADRjzur77KUv79mfp51+O6rlRvXVDQDn5lfHV2Ae6KqJKkMJDgiRJtaqGSJImDrtdb76/WX1GztHOvQe16tVRqlO9iie/FlBicnJydPPNN2v27NkXvD59+nTNmDFDs2fPVnp6usLDw9W1a1f9/vvvjjEJCQlKTU1VSkqKNm3apFOnTqlnz54qKioqdh2lukn87bfftHDhwkuOSUxMVFBQkNPxz+mJV6lCeMr/pq3Sqg9Xasq0f2rJ0vf07AtTtSj5Ta34INXTpQH4C//e/6taDUxU+8Ev6vV/bdLrz96vm2qHq7DwrO4d+4bq1ghV5qf/o9+2zFDbmHpK27RHRWfPSjqXPkrS/Pc2adGKrfp63yGNe/F9/Xt/tgb3ifXk18I1zubGw1VxcXF6/vnn1a9fP+OaZVmaOXOmJk6cqH79+ikqKkoLFy7U6dOntWTJEknSiRMnNH/+fL344ovq0qWLmjVrpsWLF2vXrl1at25dsevw6JrEFStWXPL6Tz/99Jf3GD9+vEaPHu10rsjmf0V1ofSb+eL/ONJESapXv4Eyf/lFC954Tb373Onh6gBcSkFhkX46eO7Bla++PaCYxtU18t4OGvVCinbsPajWA6cqsGJZ+fuV0ZFjp/TpW2O1/dsDkqTMwyclybFm8bx9GVmqFl7p6n4RoJjy8vKMWU673S673e7yvTIyMpSVlaVu3bo53at9+/bavHmzhg0bpu3bt6ugoMBpTGRkpKKiorR582Z17969WJ/l0Saxb9++stlssqyLP5Fm+4u5/Av9yKfzecLtenfmTK5sf9rqxsfXR2etsx6qCMDlssnmWI943slTZyRJdapXUfNG1fXMnA8lST//clS/ZB9X/ZqhTuPr1gh1bKMDXBY3PrmSmJioZ555xuncpEmTNHnyZJfvlZV17v8ghYWFOZ0PCwvTzz//7Bjj7++vSpUqGWPOv784PNokRkRE6JVXXlHfvn0veH3nzp2KiYm5ukXhmtCufUfNf22eIiIiVKdOXX333V4tfitZffve5enSAFzCM4/20prPv9XBrGMKqFBW93SPUbsW9dR75BxJUr8uzXT42CkdzPpNUfUi9c8n7tbKDd/o463fOe6RtHCd/nv4Hdr17//o632HdF+vVmpQM0yDnpjvqa8FXNKFZj0vJ0X8oz+HaJZl/WWwVpwxf+TRJjEmJkZfffXVRZvEv0oZ4b2enPDfmjN7lqY8/6yO/XZUVaqE6u67B+jhR0Z4ujQAlxBaOUDzn/+7wkMCdeLUGe3+/j/qPXKO1n9xrgkMrxKoaWP6KbRygLKOnNTbH36hxNfSnO4xe8kGlbX7afqYu1QpqLx2/fs/6vnIbGUcOuKJr4TrhDv/LN/lTi1fSHh4uKRzaWFERITjfHZ2tiNdDA8PV35+vo4dO+aUJmZnZ6tNmzbF/iyb5cEu7LPPPlNOTo569Ohxwes5OTnatm2b2rdv79J9mW4Grl+VW43ydAkA3CR3x4Wf5r0avvjxhNvu3apO0GW/12azKTU11RGoWZalyMhI/eMf/9C4ceMkSfn5+QoNDdW0adM0bNgwnThxQlWqVNHixYvVv39/SVJmZqaqVq2qVatWXRtrEtu2bXvJ6xUqVHC5QQQAAHBVafqzfKdOndIPP/zgeJ2RkaGdO3cqODhY1atXV0JCgqZMmaJ69eqpXr16mjJlisqXL69BgwZJkoKCghQfH68xY8aocuXKCg4O1tixYxUdHa0uXboUuw7+4goAAPB6pahH1LZt29SxY0fH6/PrGQcPHqzk5GSNGzdOubm5GjFihI4dO6ZWrVppzZo1CggIcLwnKSlJZcqUUf/+/ZWbm6vOnTsrOTlZvr6+xa7Do9PN7sJ0M3D9YroZuH55cro5/Sf3TTe3rH35082eRJIIAABQmqLEUqJU/8UVAAAAeAZJIgAA8Hru3ALnWkWSCAAAAANJIgAA8HqlaQuc0oIkEQAAAAaSRAAA4PUIEk00iQAAAHSJBqabAQAAYCBJBAAAXo8tcEwkiQAAADCQJAIAAK/HFjgmkkQAAAAYSBIBAIDXI0g0kSQCAADAQJIIAABAlGigSQQAAF6PLXBMTDcDAADAQJIIAAC8HlvgmEgSAQAAYCBJBAAAXo8g0USSCAAAAANJIgAAAFGigSQRAAAABpJEAADg9dgn0USSCAAAAANJIgAA8Hrsk2iiSQQAAF6PHtHEdDMAAAAMJIkAAABEiQaSRAAAABhIEgEAgNdjCxwTSSIAAAAMJIkAAMDrsQWOiSQRAAAABpJEAADg9QgSTTSJAAAAdIkGppsBAABgIEkEAABejy1wTCSJAAAAMJAkAgAAr8cWOCaSRAAAABhIEgEAgNcjSDSRJAIAAMBAkggAAECUaKBJBAAAXo8tcExMNwMAAMBAkggAALweW+CYSBIBAABKicmTJ8tmszkd4eHhjuuWZWny5MmKjIxUuXLl1KFDB+3Zs8cttdAkAgAAr2dz4+Gqxo0bKzMz03Hs2rXLcW369OmaMWOGZs+erfT0dIWHh6tr1676/fffL+drXxLTzQAAAG6Ul5envLw8p3N2u112u/2C48uUKeOUHp5nWZZmzpypiRMnql+/fpKkhQsXKiwsTEuWLNGwYcNKtG6SRAAAADdGiYmJiQoKCnI6EhMTL1rK999/r8jISNWqVUsDBw7UTz/9JEnKyMhQVlaWunXr5hhrt9vVvn17bd68uQR/jHNIEgEAANxo/PjxGj16tNO5i6WIrVq10ltvvaX69evr119/1fPPP682bdpoz549ysrKkiSFhYU5vScsLEw///xziddNkwgAALyeO/dJvNTU8p/FxcU5/h0dHa3Y2FjVqVNHCxcuVOvWrSVJtj89im1ZlnGuJDDdDAAAvJ7N5r7jSlSoUEHR0dH6/vvvHesUzyeK52VnZxvpYkmgSQQAACil8vLytHfvXkVERKhWrVoKDw/X2rVrHdfz8/O1ceNGtWnTpsQ/m+lmAADg9UrLXtpjx45Vr169VL16dWVnZ+v555/XyZMnNXjwYNlsNiUkJGjKlCmqV6+e6tWrpylTpqh8+fIaNGhQiddCkwgAAFBKHDp0SPfee6+OHDmiKlWqqHXr1tq6datq1KghSRo3bpxyc3M1YsQIHTt2TK1atdKaNWsUEBBQ4rXYLMuySvyuHnY6/7r7SgD+T+VWozxdAgA3yd0x22OffehY3l8PukxVKxXvoZXShjWJAAAAMDDdDAAAUGpWJZYeJIkAAAAwkCQCAACv54a9qK95NIkAAMDr0SOamG4GAACAgSQRAAB4PaabTSSJAAAAMJAkAgAAr2djVaKBJBEAAAAGkkQAAACCRANJIgAAAAwkiQAAwOsRJJpoEgEAgNdjCxwT080AAAAwkCQCAACvxxY4JpJEAAAAGEgSAQAACBINJIkAAAAwkCQCAACvR5BoIkkEAACAgSQRAAB4PfZJNNEkAgAAr8cWOCammwEAAGAgSQQAAF6P6WYTSSIAAAAMNIkAAAAw0CQCAADAwJpEAADg9ViTaCJJBAAAgIEkEQAAeD32STTRJAIAAK/HdLOJ6WYAAAAYSBIBAIDXI0g0kSQCAADAQJIIAABAlGggSQQAAICBJBEAAHg9tsAxkSQCAADAQJIIAAC8HvskmkgSAQAAYCBJBAAAXo8g0USTCAAAQJdoYLoZAAAABpJEAADg9dgCx0SSCAAAAANJIgAA8HpsgWMiSQQAAIDBZlmW5ekigMuVl5enxMREjR8/Xna73dPlAChB/PcNeBZNIq5pJ0+eVFBQkE6cOKHAwEBPlwOgBPHfN+BZTDcDAADAQJMIAAAAA00iAAAADDSJuKbZ7XZNmjSJRe3AdYj/vgHP4sEVAAAAGEgSAQAAYKBJBAAAgIEmEQAAAAaaRAAAABhoEnFNmzNnjmrVqqWyZcsqJiZGn332madLAnCFPv30U/Xq1UuRkZGy2Wxavny5p0sCvBJNIq5ZS5cuVUJCgiZOnKgdO3aobdu2iouL04EDBzxdGoArkJOTo5tvvlmzZ8/2dCmAV2MLHFyzWrVqpebNm2vu3LmOcw0bNlTfvn2VmJjowcoAlBSbzabU1FT17dvX06UAXockEdek/Px8bd++Xd26dXM6361bN23evNlDVQEAcP2gScQ16ciRIyoqKlJYWJjT+bCwMGVlZXmoKgAArh80ibim2Ww2p9eWZRnnAACA62gScU0KCQmRr6+vkRpmZ2cb6SIAAHAdTSKuSf7+/oqJidHatWudzq9du1Zt2rTxUFUAAFw/yni6AOByjR49Wvfff79atGih2NhYvfbaazpw4ICGDx/u6dIAXIFTp07phx9+cLzOyMjQzp07FRwcrOrVq3uwMsC7sAUOrmlz5szR9OnTlZmZqaioKCUlJaldu3aeLgvAFdiwYYM6duxonB88eLCSk5OvfkGAl6JJBAAAgIE1iQAAADDQJAIAAMBAkwgAAAADTSIAAAAMNIkAAAAw0CQCAADAQJMIAAAAA00iAAAADDSJAK7Y5MmT1bRpU8frIUOGqG/fvle9jv3798tms2nnzp0XHVOzZk3NnDmz2PdMTk7WDTfccMW12Ww2LV++/IrvAwBXC00icJ0aMmSIbDabbDab/Pz8VLt2bY0dO1Y5OTlu/+yXXnqp2H8+rTiNHQDg6ivj6QIAuE+PHj20YMECFRQU6LPPPtNDDz2knJwczZ071xhbUFAgPz+/EvncoKCgErkPAMBzSBKB65jdbld4eLiqVaumQYMG6W9/+5tjyvP8FPGbb76p2rVry263y7IsnThxQg8//LBCQ0MVGBioTp066euvv3a679SpUxUWFqaAgADFx8frzJkzTtf/PN189uxZTZs2TXXr1pXdblf16tX1wgsvSJJq1aolSWrWrJlsNps6dOjgeN+CBQvUsGFDlS1bVjfddJPmzJnj9DlffvmlmjVrprJly6pFixbasWOHy7/RjBkzFB0drQoVKqhatWoaMWKETp06ZYxbvny56tevr7Jly6pr1646ePCg0/WVK1cqJiZGZcuWVe3atfXMM8+osLDwgp+Zn5+vRx99VBERESpbtqxq1qypxMREl2sHAHciSQS8SLly5VRQUOB4/cMPP2jZsmV677335OvrK0m64447FBwcrFWrVikoKEivvvqqOnfurH//+98KDg7WsmXLNGnSJL3yyitq27atFi1apFmzZql27doX/dzx48fr9ddfV1JSkm677TZlZmbqu+++k3Su0bvlllu0bt06NW7cWP7+/pKk119/XZMmTdLs2bPVrFkz7dixQ0OHDlWFChU0ePBg5eTkqGfPnurUqZMWL16sjIwMPf744y7/Jj4+Ppo1a5Zq1qypjIwMjRgxQuPGjXNqSE+fPq0XXnhBCxculL+/v0aMGKGBAwfq888/lyT97//+r+677z7NmjVLbdu21Y8//qiHH35YkjRp0iTjM2fNmqUVK1Zo2bJlql69ug4ePGg0nQDgcRaA69LgwYOtPn36OF5/8cUXVuXKla3+/ftblmVZkyZNsvz8/Kzs7GzHmI8//tgKDAy0zpw543SvOnXqWK+++qplWZYVGxtrDR8+3Ol6q1atrJtvvvmCn33y5EnLbrdbr7/++gXrzMjIsCRZO3bscDpfrVo1a8mSJU7nnnvuOSs2NtayLMt69dVXreDgYCsnJ8dxfe7cuRe81x/VqFHDSkpKuuj1ZcuWWZUrV3a8XrBggSXJ2rp1q+Pc3r17LUnWF198YVmWZbVt29aaMmWK030WLVpkRUREOF5LslJTUy3LsqxRo0ZZnTp1ss6ePXvROgDA00gSgevYhx9+qIoVK6qwsFAFBQXq06ePXn75Zcf1GjVqqEqVKo7X27dv16lTp1S5cmWn++Tm5urHH3+UJO3du1fDhw93uh4bG6tPPvnkgjXs3btXeXl56ty5c7HrPnz4sA4ePKj4+HgNHTrUcb6wsNCx3nHv3r26+eabVb58eac6XPXJJ59oypQp+vbbb3Xy5EkVFhbqzJkzysnJUYUKFSRJZcqUUYsWLRzvuemmm3TDDTdo7969uuWWW7R9+3alp6c7ptAlqaioSGfOnNHp06edapTOTcd37dpVDRo0UI8ePdSzZ09169bN5doBwJ1oEoHrWMeOHTV37lz5+fkpMjLSeDDlfBN03tmzZxUREaENGzYY97rcbWDKlSvn8nvOnj0r6dyUc6tWrZyunZ8Wtyzrsur5o59//lm33367hg8frueee07BwcHatGmT4uPjnablpXNb2PzZ+XNnz57VM888o379+hljypYta5xr3ry5MjIytHr1aq1bt079+/dXly5d9O67717xdwKAkkKTCFzHKlSooLp16xZ7fPPmzZWVlaUyZcqoZs2aFxzTsGFDbd26VX//+98d57Zu3XrRe9arV0/lypXTxx9/rIceesi4fn4NYlFRkeNcWFiYbrzxRv3000/629/+dsH7NmrUSIsWLVJubq6jEb1UHReybds2FRYW6sUXX5SPz7nn+JYtW2aMKyws1LZt23TLLbdIkvbt26fjx4/rpptuknTud9u3b59Lv3VgYKAGDBigAQMG6O6771aPHj3022+/KTg42KXvAADuQpMIwKFLly6KjY1V3759NW3aNDVo0EC//PKLVq1apb59+6pFixZ6/PHHNXjwYLVo0UK33Xab3n77be3Zs+eiD66ULVtWTz75pMaNGyd/f3/deuutOnz4sPbs2aP4+HiFhoaqXLlySktLU9WqVVW2bFkFBQVp8uTJeuyxxxQYGKi4uDjl5eVp27ZtOnbsmEaPHq1BgwZp4sSJio+P13//939r//79+uc//+nS961Tp44KCwv18ssvq1evXvr88881b948Y5yfn59GjRqlWbNmyc/PT48++qhat27taBqffvpp9ezZU9WqVdM999wjHx8fffPNN9q1a5eef/55435JSUmKiIhQ06ZN5ePjo3/9618KDw8vkU27AaCksAUOAAebzaZVq1apXbt2evDBB1W/fn0NHDhQ+/fvV1hYmCRpwIABevrpp/Xkk08qJiZGP//8sx555JFL3vepp57SmDFj9PTTT6thw4YaMGCAsrOzJZ1b7zdr1iy9+uqrioyMVJ8+fSRJDz30kN544w0lJycrOjpa7du3V3JysmPLnIoVK2rlypX69ttv1axZM02cOFHTpk1z6fs2bdpUM2bM0LRp0xQVFaW33377glvRlC9fXk8++aQGDRqk2NhYlStXTikpKY7r3bt314cffqi1a9eqZcuWat26tWbMmKEaNWpc8HMrVqyoadOmqUWLFmrZsqX279+vVatWOdJMACgNbFZJLOwBAADAdYX/2woAAAADTSIAAAAMNIkAAAAw0CQCAADAQJMIAAAAA00iAAAADDSJAAAAMNAkAgAAwECTCAAAAANNIgAAAAw0iQAAADD8P8KHFplaREFWAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Confusion matrix per il modello lenet2\")\n",
    "eval_lenet2.print_confusion_matrix()\n",
    "print(\"\\nConfusion matrix per il modello cnn2\")\n",
    "eval_cnn2.print_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo notare come i valori di precision e recall siano molto alti per entrambi i modelli, dove la rete cnn2 ha una precision di poco maggiore, mentre la rete lenet2 ha una recall leggermente maggiore.\n",
    "La rete lenet2 ha un valore di F1 score leggermente maggiore della seconda rete.\n",
    "\n",
    "Dalla confusion matrix possiamo osservare come il test sia formato da molti dati della classe 1, di cui quasi la totalità è stata correttamente etichettata. Similmente per i dati della classe 0, che possiede meno dati. La disparità nella presenza delle classi nel test set dipende anche dal fatto che la classe 1 possiede il triplo di dati rispetto alla classe 0.\n",
    "\n",
    "Poichè la classe 1 corrisponde alle radiografie dei pazienti che presentano polmonite, si sceglie il modello con recall maggiore e con meno errori sugli elementi della classe 1, ovvero il modello lenet2. \n",
    "Quindi in conclusione si sceglie come modello migliore il modello lenet2, ovvero un modello identico al modello lenet che utilizza la relu come funzione di attivazione e MaxPooling come tipologia di pooling. I risultati migliori sono dunque i seguenti:\n",
    "\n",
    "Loss: 0.0778 \n",
    "\n",
    "Accuracy: 0.9790\n",
    "\n",
    "Precision: 0.9900\n",
    "\n",
    "Recall: 0.9827\n",
    "\n",
    "F1 Score: 0.9863g."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OSSERVAZIONI GENERALI\n",
    "\n",
    "Nella ricerca dei migliori parametri molti test non sono stati riportati nel notebook. Sono stati testati molti modelli di reti neurali con numero differenti di livelli convoluzionali, in alcuni casi il numero di layer era talmente eccessivo che il modello aveva zero capacità di generalizzazione. \n",
    "\n",
    "Sono stati testati anche differenti dimensioni per i filtri, ovvero valori 3,5,7,11. I miglior valori sono stati 5 e 3. Anche il numero di filtri è stato fatto variare. Dai vari test si è notato che un numero eccessivo come numero di filtri (come atteso) comporta overfitting. \n",
    "\n",
    "Si può notare come le reti FNN abbiamo molti più parametri delle reti CNN ed che l'addestramento delle reti FNN richiede meno tempo. Nonostante il modello migliore sia una rete CNN, anche le reti FNN hanno ottenuto risultati interessanti.\n",
    "\n",
    "Per le reti FNN sono stati testate differenti configurazioni di livelli e numero di unità per livello. La miglior configurazione sembra essere quella della rete fnn_drop, ovvero partire con un livello con numero di unità molto alto e diminuendo progressivamente il numero di unità.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMFFoeEH9usy0MDC6p3w150",
   "provenance": [
    {
     "file_id": "1G8HKhaNVlQZsc8HNx1eNwzmGiqvc4K_3",
     "timestamp": 1707507531600
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
